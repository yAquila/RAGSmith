- Evaluator ı şöyle yapabiliriz belki: Her adımdan ya da bazı adımlardan sonra evaluation yapıp o adımın bir önceki adıma göre başarıyı ne kadar arttırdığına bakılabilir (Sadece retrieval için mantıklı gibi)
- İleride hızı ve kaynak kullanım verimini/gpu load verimini artırmak için aynı modeli kullanacak olan işlemleri art arda yapıp sonra diğer modele geçilebilir, bunlar farklı configlerde olsa bile kaydedilerek böyle bir şey yapılabilir
- sonuçları grafikleştirmek lazım
- dataset üretirken json isimlendirmesi direkt article_id ile olsun ben şuanki datasette değiştirdim ama ilerisi için böyle yapalım
- en son token sayıları vs kontrol edilmeli, bazı tokenlar sayılmıyor olabilir iyice bakılmalı
- teknikler implement edildikten sonra (hyperparameter optimization aşırı uzun süreceği için) bu tekniklerin kullanıldığı makalelerden hyperparametre ve prompt'ları alıp onları kullanarak test edelim
- promptlar ayrı bir dosyada tutulsun ordan çekilsin
- GraphRAG ve HyperGraphRAG tamamlandı ama prompt değişimi veya document content kısmının değişimiyle daha iyi hale getirilebilir belki
- Token sayısına hangi llm modelinin kullanıldığı eklenebilir çünkü örneğin gemini-2.0-flash az kullanıp gemma3:4b veya hatta llama3.2:1b çok kullanan bir kombinasyon avantajlı olabilir ama şuan bunu göremyoruz.