{
  "article": {
    "id": "graphabstractdatatyp_5e108718",
    "title": "Graph (abstract data type)",
    "url": "https://en.wikipedia.org/wiki/Graph_(abstract_data_type)",
    "lang": "en",
    "created_at": "2025-07-30T10:20:16.091626",
    "content": "---\nid: graphabstractdatatyp_5e108718\nurl: https://en.wikipedia.org/wiki/Graph_(abstract_data_type)\ntitle: Graph (abstract data type)\nlang: en\ncreated_at: '2025-07-30T10:17:52.397998'\nchecksum: 6b1aeaeec543426d10756e963cfcb2ae9a99ecb1b9634c6bdf45824e80b7e8a8\noptions:\n  chunk_size: 1000\n  chunk_overlap: 200\n  split_strategy: header_aware\n  total_questions: 10\n  llm_model: gemini-2.5-pro\nstats:\n  word_count: 1482\n  char_count: 9079\n  num_chunks: 13\n  original_chunks: 17\n  filtered_out: 4\n  num_sections: 0\n---\nIn computer science, a graph is an abstract data type that is meant to implement the undirected graph and directed graph concepts from the field of graph theory within mathematics. A graph data structure consists of a finite (and possibly mutable) set of vertices (also called nodes or points), together with a set of unordered pairs of these vertices for an undirected graph or a set of ordered pairs for a directed graph. These pairs are known as edges (also called links or lines), and for a directed graph are also known as edges but also sometimes arrows or arcs. The vertices may be part of the graph structure, or may be external entities represented by integer indices or references. A graph data structure may also associate to each edge some edge value, such as a symbolic label or a numeric attribute (cost, capacity, length, etc.). == Operations == The basic operations provided by a graph data structure G usually include: adjacent(G, x, y): tests whether there is an edge from the vertex x to the vertex y; neighbors(G, x): lists all vertices y such that there is an edge from the vertex x to the vertex y; add_vertex(G, x): adds the vertex x, if it is not there; remove_vertex(G, x): removes the vertex x, if it is there; add_edge(G, x, y, z): adds the edge z from the vertex x to the vertex y, if it is not there; remove_edge(G, x, y): removes the edge from the vertex x to the vertex y, if it is there; get_vertex_value(G, x): returns the value associated with the vertex x; set_vertex_value(G, x, v): sets the value associated with the vertex x to v. Structures that associate values to the edges usually also provide: get_edge_value(G, x, y): returns the value associated with the edge (x, y); set_edge_value(G, x, y, v): sets the value associated with the edge (x, y) to v. == Common data structures for graph representation == Adjacency list Vertices are stored as records or objects, and every vertex stores a list of adjacent vertices. This data structure allows the storage of additional data on the vertices. Additional data can be stored if edges are also stored as objects, in which case each vertex stores its incident edges and each edge stores its incident vertices. Adjacency matrix A two-dimensional matrix, in which the rows represent source vertices and columns represent destination vertices. Data on edges and vertices must be stored externally. Only the cost for one edge can be stored between each pair of vertices. Incidence matrix A two-dimensional matrix, in which the rows represent the vertices and columns represent the edges. The entries indicate the incidence relation between the vertex at a row and edge at a column. The following table gives the time complexity cost of performing various operations on graphs, for each of these representations, with |V| the number of vertices and |E| the number of edges. In the matrix representations, the entries encode the cost of following an edge. The cost of edges that are not present are assumed to be ∞. Adjacency lists are generally preferred for the representation of sparse graphs, while an adjacency matrix is preferred if the graph is dense; that is, the number of edges | E | {\\displaystyle |E|} is close to the number of vertices squared, | V | 2 {\\displaystyle |V|^{2}} , or if one must be able to quickly look up if there is an edge connecting two vertices. === More efficient representation of adjacency sets === The time complexity of operations in the adjacency list representation can be improved by storing the sets of adjacent vertices in more efficient data structures, such as hash tables or balanced binary search trees (the latter representation requires that vertices are identified by elements of a linearly ordered set, such as integers or character strings). A representation of adjacent vertices via hash tables leads to an amortized average time complexity of O ( 1 ) {\\displaystyle O(1)} to test adjacency of two given vertices and to remove an edge and an amortized average time complexity of O ( deg ⁡ ( x ) ) {\\displaystyle O(\\deg(x))} to remove a given vertex x of degree deg ⁡ ( x ) {\\displaystyle \\deg(x)} . The time complexity of the other operations and the asymptotic space requirement do not change. == Parallel representations == The parallelization of graph problems faces significant challenges: Data-driven computations, unstructured problems, poor locality and high data access to computation ratio. The graph representation used for parallel architectures plays a significant role in facing those challenges. Poorly chosen representations may unnecessarily drive up the communication cost of the algorithm, which will decrease its scalability. In the following, shared and distributed memory architectures are considered. === Shared memory === In the case of a shared memory model, the graph representations used for parallel processing are the same as in the sequential case, since parallel read-only access to the graph representation (e.g. an adjacency list) is efficient in shared memory. === Distributed memory === In the distributed memory model, the usual approach is to partition the vertex set V {\\displaystyle V} of the graph into p {\\displaystyle p} sets V 0 , … , V p − 1 {\\displaystyle V_{0},\\dots ,V_{p-1}} . Here, p {\\displaystyle p} is the amount of available processing elements (PE). The vertex set partitions are then distributed to the PEs with matching index, additionally to the corresponding edges. Every PE has its own subgraph representation, where edges with an endpoint in another partition require special attention. For standard communication interfaces like MPI, the ID of the PE owning the other endpoint has to be identifiable. During computation in a distributed graph algorithms, passing information along these edges implies communication. Partitioning the graph needs to be done carefully - there is a trade-off between low communication and even size partitioning But partitioning a graph is a NP-hard problem, so it is not feasible to calculate them. Instead, the following heuristics are used. 1D partitioning: Every processor gets n / p {\\displaystyle n/p} vertices and the corresponding outgoing edges. This can be understood as a row-wise or column-wise decomposition of the adjacency matrix. For algorithms operating on this representation, this requires an All-to-All communication step as well as O ( m ) {\\displaystyle {\\mathcal {O}}(m)} message buffer sizes, as each PE potentially has outgoing edges to every other PE. 2D partitioning: Every processor gets a submatrix of the adjacency matrix. Assume the processors are aligned in a rectangle p = p r × p c {\\displaystyle p=p_{r}\\times p_{c}} , where p r {\\displaystyle p_{r}} and p c {\\displaystyle p_{c}} are the amount of processing elements in each row and column, respectively. Then each processor gets a submatrix of the adjacency matrix of dimension ( n / p r ) × ( n / p c ) {\\displaystyle (n/p_{r})\\times (n/p_{c})} . This can be visualized as a checkerboard pattern in a matrix. Therefore, each processing unit can only have outgoing edges to PEs in the same row and column. This bounds the amount of communication partners for each PE to p r + p c − 1 {\\displaystyle p_{r}+p_{c}-1} out of p = p r × p c {\\displaystyle p=p_{r}\\times p_{c}} possible ones. == Compressed representations == Graphs with trillions of edges occur in machine learning, social network analysis, and other areas. Compressed graph representations have been developed to reduce I/O and memory requirements. General techniques such as Huffman coding are applicable, but the adjacency list or adjacency matrix can be processed in specific ways to increase efficiency. == Applications of Graphs == === Breadth first search and depth first search === Breadth-first search (BFS) and depth-first search (DFS) are two closely related approaches that are used for exploring all of the nodes in a given connected component. Both start with an arbitrary node, the \"root\". Strongly connected components can also be found using graph traversals using algorithms such as Kosaraju's algorithm, which is a modified DFS. === Pathfinding === Dijkstra's Algorithm is a Pathfinding Algorithm that can be used on a positively-weighted (meaning all edge weights must be greater than or equal to 0) and/or directed graphs. This can be used to find the shortest path between two arbitrarily chosen nodes which is commonly applied in routing problems. == See also == Graph traversal for more information on graph walking strategies Graph database for graph (data structure) persistency Graph rewriting for rule based transformations of graphs (graph data structures) Graph drawing software for software, systems, and providers of systems for drawing graphs == References == == External links == Boost Graph Library: a powerful C++ graph library s.a. Boost (C++ libraries) Networkx: a Python graph library GraphMatcher a java program to align directed/undirected graphs. GraphBLAS A specification for a library interface for operations on graphs, with a particular focus on sparse graphs."
  },
  "chunks": [
    {
      "id": "graphabstractdatatyp_5e108718_c0000",
      "article_id": "graphabstractdatatyp_5e108718",
      "section": "Lead",
      "heading_path": "Lead",
      "start_char": 0,
      "end_char": 844,
      "content": "In computer science, a graph is an abstract data type that is meant to implement the undirected graph and directed graph concepts from the field of graph theory within mathematics. A graph data structure consists of a finite (and possibly mutable) set of vertices (also called nodes or points), together with a set of unordered pairs of these vertices for an undirected graph or a set of ordered pairs for a directed graph. These pairs are known as edges (also called links or lines), and for a directed graph are also known as edges but also sometimes arrows or arcs. The vertices may be part of the graph structure, or may be external entities represented by integer indices or references. A graph data structure may also associate to each edge some edge value, such as a symbolic label or a numeric attribute (cost, capacity, length, etc.).",
      "char_count": 843,
      "token_estimate": 210,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "graphabstractdatatyp_5e108718_c0001",
      "article_id": "graphabstractdatatyp_5e108718",
      "section": "== Operations ==",
      "heading_path": "== Operations ==",
      "start_char": 860,
      "end_char": 1794,
      "content": "== Operations == The basic operations provided by a graph data structure G usually include: adjacent(G, x, y): tests whether there is an edge from the vertex x to the vertex y; neighbors(G, x): lists all vertices y such that there is an edge from the vertex x to the vertex y; add_vertex(G, x): adds the vertex x, if it is not there; remove_vertex(G, x): removes the vertex x, if it is there; add_edge(G, x, y, z): adds the edge z from the vertex x to the vertex y, if it is not there; remove_edge(G, x, y): removes the edge from the vertex x to the vertex y, if it is there; get_vertex_value(G, x): returns the value associated with the vertex x; set_vertex_value(G, x, v): sets the value associated with the vertex x to v. Structures that associate values to the edges usually also provide: get_edge_value(G, x, y): returns the value associated with the edge (x, y); set_edge_value(G, x, y, v): sets the value associated with the edge (x, y) to v.",
      "char_count": 949,
      "token_estimate": 237,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "graphabstractdatatyp_5e108718_c0002",
      "article_id": "graphabstractdatatyp_5e108718",
      "section": "== Common data structures for graph representation ==",
      "heading_path": "== Common data structures for graph representation ==",
      "start_char": 1847,
      "end_char": 2718,
      "content": "== Common data structures for graph representation == Adjacency list Vertices are stored as records or objects, and every vertex stores a list of adjacent vertices. This data structure allows the storage of additional data on the vertices. Additional data can be stored if edges are also stored as objects, in which case each vertex stores its incident edges and each edge stores its incident vertices. Adjacency matrix A two-dimensional matrix, in which the rows represent source vertices and columns represent destination vertices. Data on edges and vertices must be stored externally. Only the cost for one edge can be stored between each pair of vertices. Incidence matrix A two-dimensional matrix, in which the rows represent the vertices and columns represent the edges. The entries indicate the incidence relation between the vertex at a row and edge at a column.",
      "char_count": 870,
      "token_estimate": 217,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "graphabstractdatatyp_5e108718_c0003",
      "article_id": "graphabstractdatatyp_5e108718",
      "section": "== Common data structures for graph representation ==",
      "heading_path": "== Common data structures for graph representation ==",
      "start_char": 2718,
      "end_char": 3412,
      "content": "The following table gives the time complexity cost of performing various operations on graphs, for each of these representations, with |V| the number of vertices and |E| the number of edges. In the matrix representations, the entries encode the cost of following an edge. The cost of edges that are not present are assumed to be ∞. Adjacency lists are generally preferred for the representation of sparse graphs, while an adjacency matrix is preferred if the graph is dense; that is, the number of edges | E | {\\displaystyle |E|} is close to the number of vertices squared, | V | 2 {\\displaystyle |V|^{2}} , or if one must be able to quickly look up if there is an edge connecting two vertices.",
      "char_count": 694,
      "token_estimate": 173,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "graphabstractdatatyp_5e108718_c0004",
      "article_id": "graphabstractdatatyp_5e108718",
      "section": "== = More efficient representation of adjacency sets ==",
      "heading_path": "== = More efficient representation of adjacency sets ==",
      "start_char": 3415,
      "end_char": 4230,
      "content": "== = More efficient representation of adjacency sets === The time complexity of operations in the adjacency list representation can be improved by storing the sets of adjacent vertices in more efficient data structures, such as hash tables or balanced binary search trees (the latter representation requires that vertices are identified by elements of a linearly ordered set, such as integers or character strings). A representation of adjacent vertices via hash tables leads to an amortized average time complexity of O ( 1 ) {\\displaystyle O(1)} to test adjacency of two given vertices and to remove an edge and an amortized average time complexity of O ( deg ⁡ ( x ) ) {\\displaystyle O(\\deg(x))} to remove a given vertex x of degree deg ⁡ ( x ) {\\displaystyle \\deg(x)} . The time complexity of the other operations and the asymptotic space requirement do not change.",
      "char_count": 869,
      "token_estimate": 217,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "graphabstractdatatyp_5e108718_c0005",
      "article_id": "graphabstractdatatyp_5e108718",
      "section": "== Parallel representations ==",
      "heading_path": "== Parallel representations ==",
      "start_char": 4260,
      "end_char": 4758,
      "content": "== Parallel representations == The parallelization of graph problems faces significant challenges: Data-driven computations, unstructured problems, poor locality and high data access to computation ratio. The graph representation used for parallel architectures plays a significant role in facing those challenges. Poorly chosen representations may unnecessarily drive up the communication cost of the algorithm, which will decrease its scalability. In the following, shared and distributed memory architectures are considered.",
      "char_count": 527,
      "token_estimate": 131,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "graphabstractdatatyp_5e108718_c0006",
      "article_id": "graphabstractdatatyp_5e108718",
      "section": "== = Shared memory ==",
      "heading_path": "== = Shared memory ==",
      "start_char": 4779,
      "end_char": 5030,
      "content": "== = Shared memory === In the case of a shared memory model, the graph representations used for parallel processing are the same as in the sequential case, since parallel read-only access to the graph representation (e.g. an adjacency list) is efficient in shared memory.",
      "char_count": 271,
      "token_estimate": 67,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "graphabstractdatatyp_5e108718_c0007",
      "article_id": "graphabstractdatatyp_5e108718",
      "section": "== = Distributed memory ==",
      "heading_path": "== = Distributed memory ==",
      "start_char": 5056,
      "end_char": 5839,
      "content": "== = Distributed memory === In the distributed memory model, the usual approach is to partition the vertex set V {\\displaystyle V} of the graph into p {\\displaystyle p} sets V 0 , … , V p − 1 {\\displaystyle V_{0},\\dots ,V_{p-1}} . Here, p {\\displaystyle p} is the amount of available processing elements (PE). The vertex set partitions are then distributed to the PEs with matching index, additionally to the corresponding edges. Every PE has its own subgraph representation, where edges with an endpoint in another partition require special attention. For standard communication interfaces like MPI, the ID of the PE owning the other endpoint has to be identifiable. During computation in a distributed graph algorithms, passing information along these edges implies communication.",
      "char_count": 782,
      "token_estimate": 195,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "graphabstractdatatyp_5e108718_c0008",
      "article_id": "graphabstractdatatyp_5e108718",
      "section": "== = Distributed memory ==",
      "heading_path": "== = Distributed memory ==",
      "start_char": 5839,
      "end_char": 6605,
      "content": "Partitioning the graph needs to be done carefully - there is a trade-off between low communication and even size partitioning But partitioning a graph is a NP-hard problem, so it is not feasible to calculate them. Instead, the following heuristics are used. 1D partitioning: Every processor gets n / p {\\displaystyle n/p} vertices and the corresponding outgoing edges. This can be understood as a row-wise or column-wise decomposition of the adjacency matrix. For algorithms operating on this representation, this requires an All-to-All communication step as well as O ( m ) {\\displaystyle {\\mathcal {O}}(m)} message buffer sizes, as each PE potentially has outgoing edges to every other PE. 2D partitioning: Every processor gets a submatrix of the adjacency matrix.",
      "char_count": 766,
      "token_estimate": 191,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "graphabstractdatatyp_5e108718_c0009",
      "article_id": "graphabstractdatatyp_5e108718",
      "section": "== = Distributed memory ==",
      "heading_path": "== = Distributed memory ==",
      "start_char": 6606,
      "end_char": 7326,
      "content": "Assume the processors are aligned in a rectangle p = p r × p c {\\displaystyle p=p_{r}\\times p_{c}} , where p r {\\displaystyle p_{r}} and p c {\\displaystyle p_{c}} are the amount of processing elements in each row and column, respectively. Then each processor gets a submatrix of the adjacency matrix of dimension ( n / p r ) × ( n / p c ) {\\displaystyle (n/p_{r})\\times (n/p_{c})} . This can be visualized as a checkerboard pattern in a matrix. Therefore, each processing unit can only have outgoing edges to PEs in the same row and column. This bounds the amount of communication partners for each PE to p r + p c − 1 {\\displaystyle p_{r}+p_{c}-1} out of p = p r × p c {\\displaystyle p=p_{r}\\times p_{c}} possible ones.",
      "char_count": 720,
      "token_estimate": 180,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "graphabstractdatatyp_5e108718_c0010",
      "article_id": "graphabstractdatatyp_5e108718",
      "section": "== Compressed representations ==",
      "heading_path": "== Compressed representations ==",
      "start_char": 7333,
      "end_char": 7685,
      "content": "== Compressed representations == Graphs with trillions of edges occur in machine learning, social network analysis, and other areas. Compressed graph representations have been developed to reduce I/O and memory requirements. General techniques such as Huffman coding are applicable, but the adjacency list or adjacency matrix can be processed in specific ways to increase efficiency.",
      "char_count": 383,
      "token_estimate": 95,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "graphabstractdatatyp_5e108718_c0011",
      "article_id": "graphabstractdatatyp_5e108718",
      "section": "== = Breadth first search and depth first search ==",
      "heading_path": "== = Breadth first search and depth first search ==",
      "start_char": 7765,
      "end_char": 8125,
      "content": "== = Breadth first search and depth first search === Breadth-first search (BFS) and depth-first search (DFS) are two closely related approaches that are used for exploring all of the nodes in a given connected component. Both start with an arbitrary node, the \"root\". Strongly connected components can also be found using graph traversals using algorithms such as Kosaraju's algorithm, which is a modified DFS.",
      "char_count": 410,
      "token_estimate": 102,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "graphabstractdatatyp_5e108718_c0012",
      "article_id": "graphabstractdatatyp_5e108718",
      "section": "== = Pathfinding ==",
      "heading_path": "== = Pathfinding ==",
      "start_char": 8144,
      "end_char": 8449,
      "content": "== = Pathfinding === Dijkstra's Algorithm is a Pathfinding Algorithm that can be used on a positively-weighted (meaning all edge weights must be greater than or equal to 0) and/or directed graphs. This can be used to find the shortest path between two arbitrarily chosen nodes which is commonly applied in routing problems.",
      "char_count": 323,
      "token_estimate": 80,
      "token_start": null,
      "token_end": null
    }
  ],
  "questions": {
    "total_questions": 8,
    "items": [
      {
        "question": "What is the function of the `adjacent(G, x, y)` operation in a graph data structure?",
        "answer": "The `adjacent(G, x, y)` operation tests whether there is an edge from the vertex x to the vertex y.",
        "related_chunk_ids": [
          "graphabstractdatatyp_5e108718_c0001"
        ],
        "category": "FACTUAL"
      },
      {
        "question": "In an incidence matrix used for graph representation, what do the rows and columns signify?",
        "answer": "In an incidence matrix, the rows represent the vertices and the columns represent the edges.",
        "related_chunk_ids": [
          "graphabstractdatatyp_5e108718_c0002"
        ],
        "category": "FACTUAL"
      },
      {
        "question": "What is the amortized average time complexity for testing the adjacency of two given vertices when using hash tables to represent adjacent vertices?",
        "answer": "When using hash tables to represent adjacent vertices, the amortized average time complexity to test the adjacency of two given vertices is O(1).",
        "related_chunk_ids": [
          "graphabstractdatatyp_5e108718_c0004"
        ],
        "category": "FACTUAL"
      },
      {
        "question": "Considering that a graph's abstract data type allows for associating values with edges, how do the adjacency list and adjacency matrix representations differ in their ability to store this data?",
        "answer": "An adjacency list offers more flexibility, as it allows for the storage of additional data on edges, particularly if the edges are stored as objects. In contrast, an adjacency matrix is more restrictive; it can only store a single value, such as a cost, for the edge between each pair of vertices, and any other data must be stored externally.",
        "related_chunk_ids": [
          "graphabstractdatatyp_5e108718_c0000",
          "graphabstractdatatyp_5e108718_c0001",
          "graphabstractdatatyp_5e108718_c0002"
        ],
        "category": "INTERPRETATION"
      },
      {
        "question": "How does the choice of graph representation impact performance in different computing contexts, such as parallel processing or when dealing with sparse versus dense graphs?",
        "answer": "The choice of graph representation is critical for performance and scalability, especially in parallel architectures where a poor choice can increase communication costs. For general applications, the graph's density is a key factor: adjacency lists are generally preferred for sparse graphs, while an adjacency matrix is better for dense graphs or when frequent lookups for edge existence are necessary. The performance of a chosen representation, like an adjacency list, can be further optimized by using more efficient data structures like hash tables for the adjacency sets, which improves the time complexity of certain operations.",
        "related_chunk_ids": [
          "graphabstractdatatyp_5e108718_c0003",
          "graphabstractdatatyp_5e108718_c0004",
          "graphabstractdatatyp_5e108718_c0005"
        ],
        "category": "INTERPRETATION"
      },
      {
        "question": "Why is graph partitioning a significant consideration for the distributed memory model but not for the shared memory model in parallel processing?",
        "answer": "In the shared memory model, graph partitioning is not a major consideration because all processing elements have efficient, parallel read-only access to a single, complete graph representation, similar to sequential processing. Conversely, the distributed memory model requires the graph to be partitioned, distributing subsets of vertices and edges to different processing elements. This partitioning is a significant challenge because it necessitates communication between processors for edges that cross partitions, and finding an optimal partition is an NP-hard problem, forcing the use of heuristics.",
        "related_chunk_ids": [
          "graphabstractdatatyp_5e108718_c0006",
          "graphabstractdatatyp_5e108718_c0007",
          "graphabstractdatatyp_5e108718_c0008"
        ],
        "category": "INTERPRETATION"
      },
      {
        "question": "Compare the structural characteristics and preferred use cases for adjacency lists versus adjacency matrices in graph representation.",
        "answer": "An adjacency list stores vertices as objects, with each vertex maintaining a list of its adjacent vertices. This structure is generally preferred for representing sparse graphs. In contrast, an adjacency matrix is a two-dimensional matrix where rows represent source vertices and columns represent destination vertices. This representation is preferred if the graph is dense (the number of edges is close to the number of vertices squared) or if there is a need to quickly look up the existence of an edge between two vertices.",
        "related_chunk_ids": [
          "graphabstractdatatyp_5e108718_c0002",
          "graphabstractdatatyp_5e108718_c0003"
        ],
        "category": "INTERPRETATION"
      },
      {
        "question": "Compare and contrast the 1D and 2D partitioning heuristics for distributing a graph in a distributed memory system, focusing on their approach and communication implications.",
        "answer": "Both 1D and 2D partitioning are heuristics used to address the NP-hard problem of graph partitioning for distributed systems. In 1D partitioning, each of the 'p' processors is assigned 'n/p' vertices and their outgoing edges, analogous to a row-wise or column-wise decomposition of the adjacency matrix. This can lead to high communication overhead, potentially requiring an All-to-All communication step. In contrast, 2D partitioning arranges processors in a 'pr x pc' grid, with each processor receiving a submatrix of the adjacency matrix. This significantly reduces communication overhead by limiting each processor's communication partners to only those in the same row and column of the grid, which is 'pr + pc - 1' partners.",
        "related_chunk_ids": [
          "graphabstractdatatyp_5e108718_c0007",
          "graphabstractdatatyp_5e108718_c0008",
          "graphabstractdatatyp_5e108718_c0009"
        ],
        "category": "LONG_ANSWER"
      }
    ]
  },
  "metadata": {
    "export_date": "2025-07-30T10:37:33.132Z",
    "content_format": "markdown",
    "total_chunks": 13,
    "description": "Complete article dataset including content, chunks, and generated questions"
  }
}