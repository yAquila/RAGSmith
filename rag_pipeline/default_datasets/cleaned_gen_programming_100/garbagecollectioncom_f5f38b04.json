{
  "article": {
    "id": "garbagecollectioncom_f5f38b04",
    "title": "Garbage collection (computer science)",
    "url": "https://en.wikipedia.org/wiki/Garbage_collection_(computer_science)",
    "lang": "en",
    "created_at": "2025-07-30T08:35:42.781048",
    "content": "---\nid: garbagecollectioncom_f5f38b04\nurl: https://en.wikipedia.org/wiki/Garbage_collection_(computer_science)\ntitle: Garbage collection (computer science)\nlang: en\ncreated_at: '2025-07-30T08:32:43.099577'\nchecksum: 786603b4e3511459940665a6f33bdd1ecee35db5bedb726ce57a2d449df88a5d\noptions:\n  chunk_size: 1000\n  chunk_overlap: 200\n  split_strategy: header_aware\n  total_questions: 10\n  llm_model: gemini-2.5-pro\nstats:\n  word_count: 2954\n  char_count: 19397\n  num_chunks: 25\n  original_chunks: 32\n  filtered_out: 7\n  num_sections: 0\n---\nIn computer science, garbage collection (GC) is a form of automatic memory management. The garbage collector attempts to reclaim memory that was allocated by the program, but is no longer referenced; such memory is called garbage. Garbage collection was invented by American computer scientist John McCarthy around 1959 to simplify manual memory management in Lisp. Garbage collection relieves the programmer from doing manual memory management, where the programmer specifies what objects to de-allocate and return to the memory system and when to do so. Other, similar techniques include stack allocation, region inference, and memory ownership, and combinations thereof. Garbage collection may take a significant proportion of a program's total processing time, and affect performance as a result. Resources other than memory, such as network sockets, database handles, windows, file descriptors, and device descriptors, are not typically handled by garbage collection, but rather by other methods (e.g. destructors). Some such methods de-allocate memory also. == Overview == Many programming languages require garbage collection, either as part of the language specification (e.g., RPL, Java, C#, D, Go, and most scripting languages) or effectively for practical implementation (e.g., formal languages like lambda calculus). These are said to be garbage-collected languages. Other languages, such as C and C++, were designed for use with manual memory management, but have garbage-collected implementations available. Some languages, like Ada, Modula-3, and C++/CLI, allow both garbage collection and manual memory management to co-exist in the same application by using separate heaps for collected and manually managed objects. Still others, like D, are garbage-collected but allow the user to manually delete objects or even disable garbage collection entirely when speed is required. Although many languages integrate GC into their compiler and runtime system, post-hoc GC systems also exist, such as Automatic Reference Counting (ARC). Some of these post-hoc GC systems do not require recompilation. === Advantages === GC frees the programmer from manually de-allocating memory. This helps avoid some kinds of errors: Dangling pointers, which occur when a piece of memory is freed while there are still pointers to it, and one of those pointers is dereferenced. By then the memory may have been reassigned to another use, with unpredictable results. Double free bugs, which occur when the program tries to free a region of memory that has already been freed, and perhaps already been allocated again. Certain kinds of memory leaks, in which a program fails to free memory occupied by objects that have become unreachable, which can lead to memory exhaustion. === Disadvantages === GC uses computing resources to decide which memory to free. Therefore, the penalty for the convenience of not annotating object lifetime manually in the source code is overhead, which can impair program performance. A peer-reviewed paper from 2005 concluded that GC needs five times the memory to compensate for this overhead and to perform as fast as the same program using idealized explicit memory management. The comparison however is made to a program generated by inserting deallocation calls using an oracle, implemented by collecting traces from programs run under a profiler, and the program is only correct for one particular execution of the program. Interaction with memory hierarchy effects can make this overhead intolerable in circumstances that are hard to predict or to detect in routine testing. The impact on performance was given by Apple as a reason for not adopting garbage collection in iOS, despite it being the most desired feature. The moment when the garbage is actually collected can be unpredictable, resulting in stalls (pauses to shift/free memory) scattered throughout a session. Unpredictable stalls can be unacceptable in real-time environments, in transaction processing, or in interactive programs. Incremental, concurrent, and real-time garbage collectors address these problems, with varying trade-offs. == Strategies == === Tracing === Tracing garbage collection is the most common type of garbage collection, so much so that \"garbage collection\" often refers to tracing garbage collection, rather than other methods such as reference counting. The overall strategy consists of determining which objects should be garbage collected by tracing which objects are reachable by a chain of references from certain root objects, and considering the rest as garbage and collecting them. However, there are a large number of algorithms used in implementation, with widely varying complexity and performance characteristics. === Reference counting === Reference counting garbage collection is where each object has a count of the number of references to it. Garbage is identified by having a reference count of zero. An object's reference count is incremented when a reference to it is created and decremented when a reference is destroyed. When the count reaches zero, the object's memory is reclaimed. As with manual memory management, and unlike tracing garbage collection, reference counting guarantees that objects are destroyed as soon as their last reference is destroyed, and usually only accesses memory which is either in CPU caches, in objects to be freed, or directly pointed to by those, and thus tends to not have significant negative side effects on CPU cache and virtual memory operation. There are a number of disadvantages to reference counting; this can generally be solved or mitigated by more sophisticated algorithms: Cycles If two or more objects refer to each other, they can create a cycle whereby neither will be collected as their mutual references never let their reference counts become zero. Some garbage collection systems using reference counting (like the one in CPython) use specific cycle-detecting algorithms to deal with this issue. Another strategy is to use weak references for the \"backpointers\" which create cycles. Under reference counting, a weak reference is similar to a weak reference under a tracing garbage collector. It is a special reference object whose existence does not increment the reference count of the referent object. Furthermore, a weak reference is safe in that when the referent object becomes garbage, any weak reference to it lapses, rather than being permitted to remain dangling, meaning that it turns into a predictable value, such as a null reference. Space overhead (reference count) Reference counting requires space to be allocated for each object to store its reference count. The count may be stored adjacent to the object's memory or in a side table somewhere else, but in either case, every single reference-counted object requires additional storage for its reference count. Memory space with the size of an unsigned pointer is commonly used for this task, meaning that 32 or 64 bits of reference count storage must be allocated for each object. On some systems, it may be possible to mitigate this overhead by using a tagged pointer to store the reference count in unused areas of the object's memory. Often, an architecture does not actually allow programs to access the full range of memory addresses that could be stored in its native pointer size; a certain number of high bits in the address is either ignored or required to be zero. If an object reliably has a pointer at a certain location, the reference count can be stored in the unused bits of the pointer. For example, each object in Objective-C has a pointer to its class at the beginning of its memory; on the ARM64 architecture using iOS 7, 19 unused bits of this class pointer are used to store the object's reference count. Speed overhead (increment/decrement) In naive implementations, each assignment of a reference and each reference falling out of scope often require modifications of one or more reference counters. However, in a common case when a reference is copied from an outer scope variable into an inner scope variable, such that the lifetime of the inner variable is bounded by the lifetime of the outer one, the reference incrementing can be eliminated. The outer variable \"owns\" the reference. In the programming language C++, this technique is readily implemented and demonstrated with the use of const references. Reference counting in C++ is usually implemented using \"smart pointers\" whose constructors, destructors, and assignment operators manage the references. A smart pointer can be passed by reference to a function, which avoids the need to copy-construct a new smart pointer (which would increase the reference count on entry into the function and decrease it on exit). Instead, the function receives a reference to the smart pointer which is produced inexpensively. The Deutsch-Bobrow method of reference counting capitalizes on the fact that most reference count updates are in fact generated by references stored in local variables. It ignores these references, only counting references in the heap, but before an object with reference count zero can be deleted, the system must verify with a scan of the stack and register that no other reference to it still exists. A further substantial decrease in the overhead on counter updates can be obtained by update coalescing introduced by Levanoni and Petrank. Consider a pointer that in a given interval of the execution is updated several times. It first points to an object O1, then to an object O2, and so forth until at the end of the interval it points to some object On. A reference counting algorithm would typically execute rc(O1)--, rc(O2)++, rc(O2)--, rc(O3)++, rc(O3)--, ..., rc(On)++. But most of these updates are redundant. In order to have the reference count properly evaluated at the end of the interval it is enough to perform rc(O1)-- and rc(On)++. Levanoni and Petrank measured an elimination of more than 99% of the counter updates in typical Java benchmarks. Requires atomicity When used in a multithreaded environment, these modifications (increment and decrement) may need to be atomic operations such as compare-and-swap, at least for any objects which are shared, or potentially shared among multiple threads. Atomic operations are expensive on a multiprocessor, and even more expensive if they have to be emulated with software algorithms. It is possible to avoid this issue by adding per-thread or per-CPU reference counts and only accessing the global reference count when the local reference counts become or are no longer zero (or, alternatively, using a binary tree of reference counts, or even giving up deterministic destruction in exchange for not having a global reference count at all), but this adds significant memory overhead and thus tends to be only useful in special cases (it is used, for example, in the reference counting of Linux kernel modules). Update coalescing by Levanoni and Petrank can be used to eliminate all atomic operations from the write-barrier. Counters are never updated by the program threads in the course of program execution. They are only modified by the collector which executes as a single additional thread with no synchronization. This method can be used as a stop-the-world mechanism for parallel programs, and also with a concurrent reference counting collector. Not real-time Naive implementations of reference counting do not generally provide real-time behavior, because any pointer assignment can potentially cause a number of objects bounded only by total allocated memory size to be recursively freed while the thread is unable to perform other work. It is possible to avoid this issue by delegating the freeing of unreferenced objects to other threads, at the cost of extra overhead. === Escape analysis === Escape analysis is a compile-time technique that can convert heap allocations to stack allocations, thereby reducing the amount of garbage collection to be done. This analysis determines whether an object allocated inside a function is accessible outside of it. If a function-local allocation is found to be accessible to another function or thread, the allocation is said to \"escape\" and cannot be done on the stack. Otherwise, the object may be allocated directly on the stack and released when the function returns, bypassing the heap and associated memory management costs. == Availability == Generally speaking, higher-level programming languages are more likely to have garbage collection as a standard feature. In some languages lacking built-in garbage collection, it can be added through a library, as with the Boehm garbage collector for C and C++. Most functional programming languages, such as ML, Haskell, and APL, have garbage collection built in. Lisp is especially notable as both the first functional programming language and the first language to introduce garbage collection. Other dynamic languages, such as Ruby and Julia (but not Perl 5 or PHP before version 5.3, which both use reference counting), JavaScript and ECMAScript also tend to use GC. Object-oriented programming languages such as Smalltalk, ooRexx, RPL and Java usually provide integrated garbage collection. Notable exceptions are C++ and Delphi, which have destructors. === BASIC === BASIC and Logo have often used garbage collection for variable-length data types, such as strings and lists, so as not to burden programmers with memory management details. On the Altair 8800, programs with many string variables and little string space could cause long pauses due to garbage collection. Similarly the Applesoft BASIC interpreter's garbage collection algorithm repeatedly scans the string descriptors for the string having the highest address in order to compact it toward high memory, resulting in O ( n 2 ) {\\displaystyle O(n^{2})} performance and pauses anywhere from a few seconds to a few minutes. A replacement garbage collector for Applesoft BASIC by Randy Wigginton identifies a group of strings in every pass over the heap, reducing collection time dramatically. BASIC.SYSTEM, released with ProDOS in 1983, provides a windowing garbage collector for BASIC that is many times faster. === Objective-C === While the Objective-C traditionally had no garbage collection, with the release of OS X 10.5 in 2007 Apple introduced garbage collection for Objective-C 2.0, using an in-house developed runtime collector. However, with the 2012 release of OS X 10.8, garbage collection was deprecated in favor of LLVM's automatic reference counter (ARC) that was introduced with OS X 10.7. Furthermore, since May 2015 Apple even forbade the usage of garbage collection for new OS X applications in the App Store. For iOS, garbage collection has never been introduced due to problems in application responsivity and performance; instead, iOS uses ARC. === Limited environments === Garbage collection is rarely used on embedded or real-time systems because of the usual need for very tight control over the use of limited resources. However, garbage collectors compatible with many limited environments have been developed. The Microsoft .NET Micro Framework, .NET nanoFramework and Java Platform, Micro Edition are embedded software platforms that, like their larger cousins, include garbage collection. === Java === Garbage collectors available in Java OpenJDKs virtual machine (JVM) include: Serial Parallel CMS (Concurrent Mark Sweep) G1 (Garbage-First) ZGC (Z Garbage Collector) Epsilon Shenandoah GenZGC (Generational ZGC) GenShen (Generational Shenandoah) IBM Metronome (only in IBM OpenJDK) SAP (only in SAP OpenJDK) Azul C4 (Continuously Concurrent Compacting Collector) (only in Azul Systems OpenJDK) === Compile-time use === Compile-time garbage collection is a form of static analysis allowing memory to be reused and reclaimed based on invariants known during compilation. This form of garbage collection has been studied in the Mercury programming language, and it saw greater usage with the introduction of LLVM's automatic reference counter (ARC) into Apple's ecosystem (iOS and OS X) in 2011. === Real-time systems === Incremental, concurrent, and real-time garbage collectors have been developed, for example by Henry Baker and by Henry Lieberman. In Baker's algorithm, the allocation is done in either half of a single region of memory. When it becomes half full, a garbage collection is performed which moves the live objects into the other half and the remaining objects are implicitly deallocated. The running program (the 'mutator') has to check that any object it references is in the correct half, and if not move it across, while a background task is finding all of the objects. Generational garbage collection schemes are based on the empirical observation that most objects die young. In generational garbage collection, two or more allocation regions (generations) are kept, which are kept separate based on the object's age. New objects are created in the \"young\" generation that is regularly collected, and when a generation is full, the objects that are still referenced from older regions are copied into the next oldest generation. Occasionally a full scan is performed. Some high-level language computer architectures include hardware support for real-time garbage collection. Most implementations of real-time garbage collectors use tracing. Such real-time garbage collectors meet hard real-time constraints when used with a real-time operating system. == See also == Destructor (computer programming) Dynamic dead-code elimination Smart pointer Virtual memory compression == References == == Further reading == Jones, Richard; Hosking, Antony; Moss, J. Eliot B. (2011-08-16). The Garbage Collection Handbook: The Art of Automatic Memory Management. CRC Applied Algorithms and Data Structures Series. Chapman and Hall / CRC Press / Taylor & Francis Ltd. ISBN 978-1-4200-8279-1. (511 pages) Jones, Richard; Lins, Rafael (1996-07-12). Garbage Collection: Algorithms for Automatic Dynamic Memory Management (1 ed.). Wiley. ISBN 978-0-47194148-4. (404 pages) Schorr, Herbert; Waite, William M. (August 1967). \"An Efficient Machine-Independent Procedure for Garbage Collection in Various List Structures\" (PDF). Communications of the ACM. 10 (8): 501–506. doi:10.1145/363534.363554. S2CID 5684388. Archived (PDF) from the original on 2021-01-22. Wilson, Paul R. (1992). \"Uniprocessor Garbage Collection Techniques\". Memory Management. Lecture Notes in Computer Science. Vol. 637. Springer-Verlag. pp. 1–42. CiteSeerX 10.1.1.47.2438. doi:10.1007/bfb0017182. ISBN 3-540-55940-X. {{cite book}}: |journal= ignored (help) Wilson, Paul R.; Johnstone, Mark S.; Neely, Michael; Boles, David (1995). \"Dynamic Storage Allocation: A Survey and Critical Review\". Memory Management. Lecture Notes in Computer Science. Vol. 986 (1 ed.). pp. 1–116. CiteSeerX 10.1.1.47.275. doi:10.1007/3-540-60368-9_19. ISBN 978-3-540-60368-9. {{cite book}}: |journal= ignored (help) == External links == The Memory Management Reference Archived 2020-12-13 at the Wayback Machine The Very Basics of Garbage Collection Java SE 6 HotSpot Virtual Machine Garbage Collection Tuning TinyGC - an independent implementation of the BoehmGC API Conservative Garbage Collection Implementation for C Language MeixnerGC - an incremental mark and sweep garbage collector for C++ using smart pointers"
  },
  "chunks": [
    {
      "id": "garbagecollectioncom_f5f38b04_c0000",
      "article_id": "garbagecollectioncom_f5f38b04",
      "section": "Lead",
      "heading_path": "Lead",
      "start_char": 0,
      "end_char": 801,
      "content": "In computer science, garbage collection (GC) is a form of automatic memory management. The garbage collector attempts to reclaim memory that was allocated by the program, but is no longer referenced; such memory is called garbage. Garbage collection was invented by American computer scientist John McCarthy around 1959 to simplify manual memory management in Lisp. Garbage collection relieves the programmer from doing manual memory management, where the programmer specifies what objects to de-allocate and return to the memory system and when to do so. Other, similar techniques include stack allocation, region inference, and memory ownership, and combinations thereof. Garbage collection may take a significant proportion of a program's total processing time, and affect performance as a result.",
      "char_count": 800,
      "token_estimate": 200,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "garbagecollectioncom_f5f38b04_c0001",
      "article_id": "garbagecollectioncom_f5f38b04",
      "section": "Lead",
      "heading_path": "Lead",
      "start_char": 801,
      "end_char": 1063,
      "content": "Resources other than memory, such as network sockets, database handles, windows, file descriptors, and device descriptors, are not typically handled by garbage collection, but rather by other methods (e.g. destructors). Some such methods de-allocate memory also.",
      "char_count": 262,
      "token_estimate": 65,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "garbagecollectioncom_f5f38b04_c0002",
      "article_id": "garbagecollectioncom_f5f38b04",
      "section": "== Overview ==",
      "heading_path": "== Overview ==",
      "start_char": 1078,
      "end_char": 2059,
      "content": "== Overview == Many programming languages require garbage collection, either as part of the language specification (e.g., RPL, Java, C#, D, Go, and most scripting languages) or effectively for practical implementation (e.g., formal languages like lambda calculus). These are said to be garbage-collected languages. Other languages, such as C and C++, were designed for use with manual memory management, but have garbage-collected implementations available. Some languages, like Ada, Modula-3, and C++/CLI, allow both garbage collection and manual memory management to co-exist in the same application by using separate heaps for collected and manually managed objects. Still others, like D, are garbage-collected but allow the user to manually delete objects or even disable garbage collection entirely when speed is required. Although many languages integrate GC into their compiler and runtime system, post-hoc GC systems also exist, such as Automatic Reference Counting (ARC).",
      "char_count": 980,
      "token_estimate": 245,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "garbagecollectioncom_f5f38b04_c0003",
      "article_id": "garbagecollectioncom_f5f38b04",
      "section": "== = Advantages ==",
      "heading_path": "== = Advantages ==",
      "start_char": 2127,
      "end_char": 2769,
      "content": "== = Advantages === GC frees the programmer from manually de-allocating memory. This helps avoid some kinds of errors: Dangling pointers, which occur when a piece of memory is freed while there are still pointers to it, and one of those pointers is dereferenced. By then the memory may have been reassigned to another use, with unpredictable results. Double free bugs, which occur when the program tries to free a region of memory that has already been freed, and perhaps already been allocated again. Certain kinds of memory leaks, in which a program fails to free memory occupied by objects that have become unreachable, which can lead to memory exhaustion.",
      "char_count": 659,
      "token_estimate": 164,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "garbagecollectioncom_f5f38b04_c0004",
      "article_id": "garbagecollectioncom_f5f38b04",
      "section": "== = Disadvantages ==",
      "heading_path": "== = Disadvantages ==",
      "start_char": 2790,
      "end_char": 3627,
      "content": "== = Disadvantages === GC uses computing resources to decide which memory to free. Therefore, the penalty for the convenience of not annotating object lifetime manually in the source code is overhead, which can impair program performance. A peer-reviewed paper from 2005 concluded that GC needs five times the memory to compensate for this overhead and to perform as fast as the same program using idealized explicit memory management. The comparison however is made to a program generated by inserting deallocation calls using an oracle, implemented by collecting traces from programs run under a profiler, and the program is only correct for one particular execution of the program. Interaction with memory hierarchy effects can make this overhead intolerable in circumstances that are hard to predict or to detect in routine testing.",
      "char_count": 836,
      "token_estimate": 209,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "garbagecollectioncom_f5f38b04_c0005",
      "article_id": "garbagecollectioncom_f5f38b04",
      "section": "== = Disadvantages ==",
      "heading_path": "== = Disadvantages ==",
      "start_char": 3627,
      "end_char": 4154,
      "content": "The impact on performance was given by Apple as a reason for not adopting garbage collection in iOS, despite it being the most desired feature. The moment when the garbage is actually collected can be unpredictable, resulting in stalls (pauses to shift/free memory) scattered throughout a session. Unpredictable stalls can be unacceptable in real-time environments, in transaction processing, or in interactive programs. Incremental, concurrent, and real-time garbage collectors address these problems, with varying trade-offs.",
      "char_count": 527,
      "token_estimate": 131,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "garbagecollectioncom_f5f38b04_c0006",
      "article_id": "garbagecollectioncom_f5f38b04",
      "section": "== = Tracing ==",
      "heading_path": "== = Tracing ==",
      "start_char": 4166,
      "end_char": 4748,
      "content": "== = Tracing === Tracing garbage collection is the most common type of garbage collection, so much so that \"garbage collection\" often refers to tracing garbage collection, rather than other methods such as reference counting. The overall strategy consists of determining which objects should be garbage collected by tracing which objects are reachable by a chain of references from certain root objects, and considering the rest as garbage and collecting them. However, there are a large number of algorithms used in implementation, with widely varying complexity and performance characteristics.",
      "char_count": 596,
      "token_estimate": 149,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "garbagecollectioncom_f5f38b04_c0007",
      "article_id": "garbagecollectioncom_f5f38b04",
      "section": "== = Reference counting ==",
      "heading_path": "== = Reference counting ==",
      "start_char": 4774,
      "end_char": 5555,
      "content": "== = Reference counting === Reference counting garbage collection is where each object has a count of the number of references to it. Garbage is identified by having a reference count of zero. An object's reference count is incremented when a reference to it is created and decremented when a reference is destroyed. When the count reaches zero, the object's memory is reclaimed. As with manual memory management, and unlike tracing garbage collection, reference counting guarantees that objects are destroyed as soon as their last reference is destroyed, and usually only accesses memory which is either in CPU caches, in objects to be freed, or directly pointed to by those, and thus tends to not have significant negative side effects on CPU cache and virtual memory operation.",
      "char_count": 780,
      "token_estimate": 195,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "garbagecollectioncom_f5f38b04_c0008",
      "article_id": "garbagecollectioncom_f5f38b04",
      "section": "== = Reference counting ==",
      "heading_path": "== = Reference counting ==",
      "start_char": 5555,
      "end_char": 6327,
      "content": "There are a number of disadvantages to reference counting; this can generally be solved or mitigated by more sophisticated algorithms: Cycles If two or more objects refer to each other, they can create a cycle whereby neither will be collected as their mutual references never let their reference counts become zero. Some garbage collection systems using reference counting (like the one in CPython) use specific cycle-detecting algorithms to deal with this issue. Another strategy is to use weak references for the \"backpointers\" which create cycles. Under reference counting, a weak reference is similar to a weak reference under a tracing garbage collector. It is a special reference object whose existence does not increment the reference count of the referent object.",
      "char_count": 772,
      "token_estimate": 193,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "garbagecollectioncom_f5f38b04_c0009",
      "article_id": "garbagecollectioncom_f5f38b04",
      "section": "== = Reference counting ==",
      "heading_path": "== = Reference counting ==",
      "start_char": 6328,
      "end_char": 7229,
      "content": "Furthermore, a weak reference is safe in that when the referent object becomes garbage, any weak reference to it lapses, rather than being permitted to remain dangling, meaning that it turns into a predictable value, such as a null reference. Space overhead (reference count) Reference counting requires space to be allocated for each object to store its reference count. The count may be stored adjacent to the object's memory or in a side table somewhere else, but in either case, every single reference-counted object requires additional storage for its reference count. Memory space with the size of an unsigned pointer is commonly used for this task, meaning that 32 or 64 bits of reference count storage must be allocated for each object. On some systems, it may be possible to mitigate this overhead by using a tagged pointer to store the reference count in unused areas of the object's memory.",
      "char_count": 901,
      "token_estimate": 225,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "garbagecollectioncom_f5f38b04_c0010",
      "article_id": "garbagecollectioncom_f5f38b04",
      "section": "== = Reference counting ==",
      "heading_path": "== = Reference counting ==",
      "start_char": 7230,
      "end_char": 8014,
      "content": "Often, an architecture does not actually allow programs to access the full range of memory addresses that could be stored in its native pointer size; a certain number of high bits in the address is either ignored or required to be zero. If an object reliably has a pointer at a certain location, the reference count can be stored in the unused bits of the pointer. For example, each object in Objective-C has a pointer to its class at the beginning of its memory; on the ARM64 architecture using iOS 7, 19 unused bits of this class pointer are used to store the object's reference count. Speed overhead (increment/decrement) In naive implementations, each assignment of a reference and each reference falling out of scope often require modifications of one or more reference counters.",
      "char_count": 784,
      "token_estimate": 196,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "garbagecollectioncom_f5f38b04_c0011",
      "article_id": "garbagecollectioncom_f5f38b04",
      "section": "== = Reference counting ==",
      "heading_path": "== = Reference counting ==",
      "start_char": 8015,
      "end_char": 8888,
      "content": "However, in a common case when a reference is copied from an outer scope variable into an inner scope variable, such that the lifetime of the inner variable is bounded by the lifetime of the outer one, the reference incrementing can be eliminated. The outer variable \"owns\" the reference. In the programming language C++, this technique is readily implemented and demonstrated with the use of const references. Reference counting in C++ is usually implemented using \"smart pointers\" whose constructors, destructors, and assignment operators manage the references. A smart pointer can be passed by reference to a function, which avoids the need to copy-construct a new smart pointer (which would increase the reference count on entry into the function and decrease it on exit). Instead, the function receives a reference to the smart pointer which is produced inexpensively.",
      "char_count": 873,
      "token_estimate": 218,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "garbagecollectioncom_f5f38b04_c0012",
      "article_id": "garbagecollectioncom_f5f38b04",
      "section": "== = Reference counting ==",
      "heading_path": "== = Reference counting ==",
      "start_char": 8889,
      "end_char": 9809,
      "content": "The Deutsch-Bobrow method of reference counting capitalizes on the fact that most reference count updates are in fact generated by references stored in local variables. It ignores these references, only counting references in the heap, but before an object with reference count zero can be deleted, the system must verify with a scan of the stack and register that no other reference to it still exists. A further substantial decrease in the overhead on counter updates can be obtained by update coalescing introduced by Levanoni and Petrank. Consider a pointer that in a given interval of the execution is updated several times. It first points to an object O1, then to an object O2, and so forth until at the end of the interval it points to some object On. A reference counting algorithm would typically execute rc(O1)--, rc(O2)++, rc(O2)--, rc(O3)++, rc(O3)--, ..., rc(On)++. But most of these updates are redundant.",
      "char_count": 920,
      "token_estimate": 230,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "garbagecollectioncom_f5f38b04_c0013",
      "article_id": "garbagecollectioncom_f5f38b04",
      "section": "== = Reference counting ==",
      "heading_path": "== = Reference counting ==",
      "start_char": 9810,
      "end_char": 10438,
      "content": "In order to have the reference count properly evaluated at the end of the interval it is enough to perform rc(O1)-- and rc(On)++. Levanoni and Petrank measured an elimination of more than 99% of the counter updates in typical Java benchmarks. Requires atomicity When used in a multithreaded environment, these modifications (increment and decrement) may need to be atomic operations such as compare-and-swap, at least for any objects which are shared, or potentially shared among multiple threads. Atomic operations are expensive on a multiprocessor, and even more expensive if they have to be emulated with software algorithms.",
      "char_count": 628,
      "token_estimate": 157,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "garbagecollectioncom_f5f38b04_c0014",
      "article_id": "garbagecollectioncom_f5f38b04",
      "section": "== = Reference counting ==",
      "heading_path": "== = Reference counting ==",
      "start_char": 10439,
      "end_char": 11408,
      "content": "It is possible to avoid this issue by adding per-thread or per-CPU reference counts and only accessing the global reference count when the local reference counts become or are no longer zero (or, alternatively, using a binary tree of reference counts, or even giving up deterministic destruction in exchange for not having a global reference count at all), but this adds significant memory overhead and thus tends to be only useful in special cases (it is used, for example, in the reference counting of Linux kernel modules). Update coalescing by Levanoni and Petrank can be used to eliminate all atomic operations from the write-barrier. Counters are never updated by the program threads in the course of program execution. They are only modified by the collector which executes as a single additional thread with no synchronization. This method can be used as a stop-the-world mechanism for parallel programs, and also with a concurrent reference counting collector.",
      "char_count": 969,
      "token_estimate": 242,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "garbagecollectioncom_f5f38b04_c0015",
      "article_id": "garbagecollectioncom_f5f38b04",
      "section": "== = Reference counting ==",
      "heading_path": "== = Reference counting ==",
      "start_char": 11409,
      "end_char": 11836,
      "content": "Not real-time Naive implementations of reference counting do not generally provide real-time behavior, because any pointer assignment can potentially cause a number of objects bounded only by total allocated memory size to be recursively freed while the thread is unable to perform other work. It is possible to avoid this issue by delegating the freeing of unreferenced objects to other threads, at the cost of extra overhead.",
      "char_count": 427,
      "token_estimate": 106,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "garbagecollectioncom_f5f38b04_c0016",
      "article_id": "garbagecollectioncom_f5f38b04",
      "section": "== = Escape analysis ==",
      "heading_path": "== = Escape analysis ==",
      "start_char": 11834,
      "end_char": 12414,
      "content": "== = Escape analysis === Escape analysis is a compile-time technique that can convert heap allocations to stack allocations, thereby reducing the amount of garbage collection to be done. This analysis determines whether an object allocated inside a function is accessible outside of it. If a function-local allocation is found to be accessible to another function or thread, the allocation is said to \"escape\" and cannot be done on the stack. Otherwise, the object may be allocated directly on the stack and released when the function returns, bypassing the heap and associated memory management costs.",
      "char_count": 602,
      "token_estimate": 150,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "garbagecollectioncom_f5f38b04_c0017",
      "article_id": "garbagecollectioncom_f5f38b04",
      "section": "== Availability ==",
      "heading_path": "== Availability ==",
      "start_char": 12432,
      "end_char": 13293,
      "content": "== Availability == Generally speaking, higher-level programming languages are more likely to have garbage collection as a standard feature. In some languages lacking built-in garbage collection, it can be added through a library, as with the Boehm garbage collector for C and C++. Most functional programming languages, such as ML, Haskell, and APL, have garbage collection built in. Lisp is especially notable as both the first functional programming language and the first language to introduce garbage collection. Other dynamic languages, such as Ruby and Julia (but not Perl 5 or PHP before version 5.3, which both use reference counting), JavaScript and ECMAScript also tend to use GC. Object-oriented programming languages such as Smalltalk, ooRexx, RPL and Java usually provide integrated garbage collection. Notable exceptions are C++ and Delphi, which have destructors.",
      "char_count": 878,
      "token_estimate": 219,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "garbagecollectioncom_f5f38b04_c0018",
      "article_id": "garbagecollectioncom_f5f38b04",
      "section": "== = BASIC ==",
      "heading_path": "== = BASIC ==",
      "start_char": 13306,
      "end_char": 14216,
      "content": "== = BASIC === BASIC and Logo have often used garbage collection for variable-length data types, such as strings and lists, so as not to burden programmers with memory management details. On the Altair 8800, programs with many string variables and little string space could cause long pauses due to garbage collection. Similarly the Applesoft BASIC interpreter's garbage collection algorithm repeatedly scans the string descriptors for the string having the highest address in order to compact it toward high memory, resulting in O ( n 2 ) {\\displaystyle O(n^{2})} performance and pauses anywhere from a few seconds to a few minutes. A replacement garbage collector for Applesoft BASIC by Randy Wigginton identifies a group of strings in every pass over the heap, reducing collection time dramatically. BASIC.SYSTEM, released with ProDOS in 1983, provides a windowing garbage collector for BASIC that is many times faster.",
      "char_count": 922,
      "token_estimate": 230,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "garbagecollectioncom_f5f38b04_c0019",
      "article_id": "garbagecollectioncom_f5f38b04",
      "section": "== = Objective-C ==",
      "heading_path": "== = Objective-C ==",
      "start_char": 14235,
      "end_char": 14871,
      "content": "== = Objective-C === While the Objective-C traditionally had no garbage collection, with the release of OS X 10.5 in 2007 Apple introduced garbage collection for Objective-C 2.0, using an in-house developed runtime collector. However, with the 2012 release of OS X 10.8, garbage collection was deprecated in favor of LLVM's automatic reference counter (ARC) that was introduced with OS X 10.7. Furthermore, since May 2015 Apple even forbade the usage of garbage collection for new OS X applications in the App Store. For iOS, garbage collection has never been introduced due to problems in application responsivity and performance; instead, iOS uses ARC.",
      "char_count": 654,
      "token_estimate": 163,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "garbagecollectioncom_f5f38b04_c0020",
      "article_id": "garbagecollectioncom_f5f38b04",
      "section": "== = Limited environments ==",
      "heading_path": "== = Limited environments ==",
      "start_char": 14899,
      "end_char": 15324,
      "content": "== = Limited environments === Garbage collection is rarely used on embedded or real-time systems because of the usual need for very tight control over the use of limited resources. However, garbage collectors compatible with many limited environments have been developed. The Microsoft .NET Micro Framework, .NET nanoFramework and Java Platform, Micro Edition are embedded software platforms that, like their larger cousins, include garbage collection.",
      "char_count": 452,
      "token_estimate": 113,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "garbagecollectioncom_f5f38b04_c0021",
      "article_id": "garbagecollectioncom_f5f38b04",
      "section": "== = Java ==",
      "heading_path": "== = Java ==",
      "start_char": 15336,
      "end_char": 15731,
      "content": "== = Java === Garbage collectors available in Java OpenJDKs virtual machine (JVM) include: Serial Parallel CMS (Concurrent Mark Sweep) G1 (Garbage-First) ZGC (Z Garbage Collector) Epsilon Shenandoah GenZGC (Generational ZGC) GenShen (Generational Shenandoah) IBM Metronome (only in IBM OpenJDK) SAP (only in SAP OpenJDK) Azul C4 (Continuously Concurrent Compacting Collector) (only in Azul Systems OpenJDK)",
      "char_count": 406,
      "token_estimate": 101,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "garbagecollectioncom_f5f38b04_c0022",
      "article_id": "garbagecollectioncom_f5f38b04",
      "section": "== = Compile-time use ==",
      "heading_path": "== = Compile-time use ==",
      "start_char": 15755,
      "end_char": 16131,
      "content": "== = Compile-time use === Compile-time garbage collection is a form of static analysis allowing memory to be reused and reclaimed based on invariants known during compilation. This form of garbage collection has been studied in the Mercury programming language, and it saw greater usage with the introduction of LLVM's automatic reference counter (ARC) into Apple's ecosystem (iOS and OS X) in 2011.",
      "char_count": 399,
      "token_estimate": 99,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "garbagecollectioncom_f5f38b04_c0023",
      "article_id": "garbagecollectioncom_f5f38b04",
      "section": "== = Real-time systems ==",
      "heading_path": "== = Real-time systems ==",
      "start_char": 16156,
      "end_char": 17002,
      "content": "== = Real-time systems === Incremental, concurrent, and real-time garbage collectors have been developed, for example by Henry Baker and by Henry Lieberman. In Baker's algorithm, the allocation is done in either half of a single region of memory. When it becomes half full, a garbage collection is performed which moves the live objects into the other half and the remaining objects are implicitly deallocated. The running program (the 'mutator') has to check that any object it references is in the correct half, and if not move it across, while a background task is finding all of the objects. Generational garbage collection schemes are based on the empirical observation that most objects die young. In generational garbage collection, two or more allocation regions (generations) are kept, which are kept separate based on the object's age.",
      "char_count": 845,
      "token_estimate": 211,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "garbagecollectioncom_f5f38b04_c0024",
      "article_id": "garbagecollectioncom_f5f38b04",
      "section": "== = Real-time systems ==",
      "heading_path": "== = Real-time systems ==",
      "start_char": 17002,
      "end_char": 17535,
      "content": "New objects are created in the \"young\" generation that is regularly collected, and when a generation is full, the objects that are still referenced from older regions are copied into the next oldest generation. Occasionally a full scan is performed. Some high-level language computer architectures include hardware support for real-time garbage collection. Most implementations of real-time garbage collectors use tracing. Such real-time garbage collectors meet hard real-time constraints when used with a real-time operating system.",
      "char_count": 533,
      "token_estimate": 133,
      "token_start": null,
      "token_end": null
    }
  ],
  "questions": {
    "total_questions": 10,
    "items": [
      {
        "question": "Which programming languages are listed as having been designed for manual memory management but also have garbage-collected implementations available?",
        "answer": "C and C++ were designed for use with manual memory management but have garbage-collected implementations available.",
        "related_chunk_ids": [
          "garbagecollectioncom_f5f38b04_c0002"
        ],
        "category": "FACTUAL"
      },
      {
        "question": "What is a specific example of where per-thread or per-CPU reference counting is utilized despite its memory overhead?",
        "answer": "Per-thread or per-CPU reference counting is used in the reference counting of Linux kernel modules.",
        "related_chunk_ids": [
          "garbagecollectioncom_f5f38b04_c0014"
        ],
        "category": "FACTUAL"
      },
      {
        "question": "What was the performance complexity of the Applesoft BASIC interpreter's garbage collection algorithm, and what was its impact on program execution?",
        "answer": "The Applesoft BASIC interpreter's garbage collection algorithm had O(n^2) performance, which resulted in pauses that could last from a few seconds to a few minutes.",
        "related_chunk_ids": [
          "garbagecollectioncom_f5f38b04_c0018"
        ],
        "category": "FACTUAL"
      },
      {
        "question": "Provide a comprehensive overview of garbage collection, including its primary function, the types of resources it manages, and how its implementation varies across different programming languages.",
        "answer": "Garbage collection (GC) is a form of automatic memory management that reclaims memory allocated by a program but no longer referenced, relieving the programmer from manual de-allocation. While GC focuses on memory, it does not typically handle other resources like network sockets, database handles, or file descriptors. The integration of GC varies by programming language: some languages like Java and Go require it, others like C and C++ were designed for manual management but have GC implementations available, and some like Ada and Modula-3 allow both GC and manual memory management to coexist.",
        "related_chunk_ids": [
          "garbagecollectioncom_f5f38b04_c0000",
          "garbagecollectioncom_f5f38b04_c0001",
          "garbagecollectioncom_f5f38b04_c0002"
        ],
        "category": "LONG_ANSWER"
      },
      {
        "question": "What are the primary trade-offs between the advantages and disadvantages of using garbage collection for memory management?",
        "answer": "The primary advantage of garbage collection (GC) is that it frees programmers from manually de-allocating memory, which helps prevent errors like dangling pointers, double free bugs, and certain memory leaks. However, this convenience comes at the cost of performance. The main disadvantages are the overhead from using computing resources to manage memory, which can impair program performance, and the unpredictability of when collection occurs. These unpredictable stalls can be unacceptable for real-time, interactive, or transaction-processing applications, a concern that led Apple to not adopt GC for iOS.",
        "related_chunk_ids": [
          "garbagecollectioncom_f5f38b04_c0003",
          "garbagecollectioncom_f5f38b04_c0004",
          "garbagecollectioncom_f5f38b04_c0005"
        ],
        "category": "LONG_ANSWER"
      },
      {
        "question": "Compare the fundamental approaches of tracing and reference counting for identifying garbage, and describe a significant challenge unique to reference counting.",
        "answer": "Tracing garbage collection identifies garbage by determining which objects are reachable through a chain of references from root objects; any object not traced is considered garbage. In contrast, reference counting garbage collection identifies garbage when an object's reference count drops to zero, indicating no more references point to it. A significant challenge unique to reference counting is handling cycles, where two or more objects refer to each other, preventing their reference counts from ever becoming zero and thus not being collected without special cycle-detecting algorithms.",
        "related_chunk_ids": [
          "garbagecollectioncom_f5f38b04_c0006",
          "garbagecollectioncom_f5f38b04_c0007",
          "garbagecollectioncom_f5f38b04_c0008"
        ],
        "category": "INTERPRETATION"
      },
      {
        "question": "What is the scope of garbage collection in terms of resource management, and what types of resources are typically handled by other methods?",
        "answer": "Garbage collection is a form of automatic memory management that reclaims memory no longer referenced by a program. It does not typically handle other resources such as network sockets, database handles, windows, file descriptors, and device descriptors, which are managed by different methods like destructors.",
        "related_chunk_ids": [
          "garbagecollectioncom_f5f38b04_c0000",
          "garbagecollectioncom_f5f38b04_c0001"
        ],
        "category": "INTERPRETATION"
      },
      {
        "question": "What are the primary performance-related disadvantages of using garbage collection?",
        "answer": "The primary performance disadvantages of garbage collection are its resource overhead and its unpredictability. GC uses computing resources to function, which creates an overhead that can impair program performance and may require significantly more memory to match the speed of explicit memory management. Additionally, the moment when garbage is collected is unpredictable, which can result in stalls or pauses. These unpredictable stalls are particularly problematic for real-time environments, transaction processing, and interactive programs, and this performance impact was cited by Apple as a reason for not using GC in iOS.",
        "related_chunk_ids": [
          "garbagecollectioncom_f5f38b04_c0004",
          "garbagecollectioncom_f5f38b04_c0005"
        ],
        "category": "LONG_ANSWER"
      },
      {
        "question": "Summarize the main disadvantages of reference counting garbage collection and the corresponding strategies used to mitigate them.",
        "answer": "Reference counting has several disadvantages. First, it can fail to collect objects involved in a cycle, where two or more objects refer to each other, preventing their reference counts from ever reaching zero. This can be addressed by using specific cycle-detecting algorithms or by employing weak references, which do not increment the reference count. Second, it introduces space overhead, as every object requires additional storage for its reference count. This can be mitigated by using tagged pointers, which store the count in unused bits of an object's existing pointers, such as the class pointer in Objective-C on ARM64. Lastly, it can have a speed overhead due to the frequent increment and decrement operations required on reference counters for each reference assignment.",
        "related_chunk_ids": [
          "garbagecollectioncom_f5f38b04_c0007",
          "garbagecollectioncom_f5f38b04_c0008",
          "garbagecollectioncom_f5f38b04_c0009",
          "garbagecollectioncom_f5f38b04_c0010"
        ],
        "category": "LONG_ANSWER"
      },
      {
        "question": "How does the generational garbage collection scheme operate, and what empirical observation is it based on?",
        "answer": "Generational garbage collection is based on the empirical observation that most objects die young. In this scheme, two or more allocation regions, or generations, are maintained and separated based on object age. New objects are created in the \"young\" generation, which is collected regularly. When a generation fills up, the objects that are still referenced from older regions are moved into the next oldest generation. Occasionally, a full scan of all objects is performed.",
        "related_chunk_ids": [
          "garbagecollectioncom_f5f38b04_c0023",
          "garbagecollectioncom_f5f38b04_c0024"
        ],
        "category": "LONG_ANSWER"
      }
    ]
  },
  "metadata": {
    "export_date": "2025-07-30T10:37:32.680Z",
    "content_format": "markdown",
    "total_chunks": 25,
    "description": "Complete article dataset including content, chunks, and generated questions"
  }
}