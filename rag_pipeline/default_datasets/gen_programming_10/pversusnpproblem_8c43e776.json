{
  "article": {
    "id": "pversusnpproblem_8c43e776",
    "title": "P versus NP problem",
    "url": "https://en.wikipedia.org/wiki/P_versus_NP_problem",
    "lang": "en",
    "created_at": "2025-07-28T12:12:07.199432",
    "content": "---\nid: pversusnpproblem_8c43e776\nurl: https://en.wikipedia.org/wiki/P_versus_NP_problem\ntitle: P versus NP problem\nlang: en\ncreated_at: '2025-07-28T12:09:46.846363'\nchecksum: 8cbbfb4d5edfdcb72c192f27ad5d5a24ff82a14209f4a0653d619d0a8c4f0b2e\noptions:\n  chunk_size: 1000\n  chunk_overlap: 200\n  split_strategy: header_aware\n  total_questions: 10\n  llm_model: gpt-4.1\nstats:\n  word_count: 5373\n  char_count: 32065\n  num_chunks: 45\n  num_sections: 0\n---\nThe P versus NP problem is a major unsolved problem in theoretical computer science. Informally, it asks whether every problem whose solution can be quickly verified can also be quickly solved. Here, \"quickly\" means an algorithm exists that solves the task and runs in polynomial time (as opposed to, say, exponential time), meaning the task completion time is bounded above by a polynomial function on the size of the input to the algorithm. The general class of questions that some algorithm can answer in polynomial time is \"P\" or \"class P\". For some questions, there is no known way to find an answer quickly, but if provided with an answer, it can be verified quickly. The class of questions where an answer can be verified in polynomial time is \"NP\", standing for \"nondeterministic polynomial time\". An answer to the P versus NP question would determine whether problems that can be verified in polynomial time can also be solved in polynomial time. If P ≠ NP, which is widely believed, it would mean that there are problems in NP that are harder to compute than to verify: they could not be solved in polynomial time, but the answer could be verified in polynomial time. The problem has been called the most important open problem in computer science. Aside from being an important problem in computational theory, a proof either way would have profound implications for mathematics, cryptography, algorithm research, artificial intelligence, game theory, multimedia processing, philosophy, economics and many other fields. It is one of the seven Millennium Prize Problems selected by the Clay Mathematics Institute, each of which carries a US$1,000,000 prize for the first correct solution. == Example == Consider the following yes/no problem: given an incomplete Sudoku grid of size n 2 × n 2 {\\displaystyle n^{2}\\times n^{2}} , is there at least one legal solution where every row, column, and n × n {\\displaystyle n\\times n} square contains the integers 1 through n 2 {\\displaystyle n^{2}} ? It is straightforward to verify \"yes\" instances of this generalized Sudoku problem given a candidate solution. However, it is not known whether there is a polynomial-time algorithm that can correctly answer \"yes\" or \"no\" to all instances of this problem. Therefore, generalized Sudoku is in NP (quickly verifiable), but may or may not be in P (quickly solvable). (It is necessary to consider a generalized version of Sudoku, as any fixed size Sudoku has only a finite number of possible grids. In this case the problem is in P, as the answer can be found by table lookup.) == History == The precise statement of the P versus NP problem was introduced in 1971 by Stephen Cook in his seminal paper \"The complexity of theorem proving procedures\" (and independently by Leonid Levin in 1973). Although the P versus NP problem was formally defined in 1971, there were previous inklings of the problems involved, the difficulty of proof, and the potential consequences. In 1955, mathematician John Nash wrote a letter to the National Security Agency, speculating that the time required to crack a sufficiently complex code would increase exponentially with the length of the key. If proved (and Nash was suitably skeptical), this would imply what is now called P ≠ NP, since a proposed key can be verified in polynomial time. Another mention of the underlying problem occurred in a 1956 letter written by Kurt Gödel to John von Neumann. Gödel asked whether theorem-proving (now known to be co-NP-complete) could be solved in quadratic or linear time, and pointed out one of the most important consequences—that if so, then the discovery of mathematical proofs could be automated. == Context == The relation between the complexity classes P and NP is studied in computational complexity theory, the part of the theory of computation dealing with the resources required during computation to solve a given problem. The most common resources are time (how many steps it takes to solve a problem) and space (how much memory it takes to solve a problem). In such analysis, a model of the computer for which time must be analyzed is required. Typically such models assume that the computer is deterministic (given the computer's present state and any inputs, there is only one possible action that the computer might take) and sequential (it performs actions one after the other). In this theory, the class P consists of all decision problems (defined below) solvable on a deterministic sequential machine in a duration polynomial in the size of the input; the class NP consists of all decision problems whose positive solutions are verifiable in polynomial time given the right information, or equivalently, whose solution can be found in polynomial time on a non-deterministic machine. Clearly, P ⊆ NP. Arguably, the biggest open question in theoretical computer science concerns the relationship between those two classes: Is P equal to NP? Since 2002, William Gasarch has conducted three polls of researchers concerning this and related questions. Confidence that P ≠ NP has been increasing – in 2019, 88% believed P ≠ NP, as opposed to 83% in 2012 and 61% in 2002. When restricted to experts, the 2019 answers became 99% believed P ≠ NP. These polls do not imply whether P = NP, Gasarch himself stated: \"This does not bring us any closer to solving P=?NP or to knowing when it will be solved, but it attempts to be an objective report on the subjective opinion of this era.\" == NP-completeness == To attack the P = NP question, the concept of NP-completeness is very useful. NP-complete problems are problems that any other NP problem is reducible to in polynomial time and whose solution is still verifiable in polynomial time. That is, any NP problem can be transformed into any NP-complete problem. Informally, an NP-complete problem is an NP problem that is at least as \"tough\" as any other problem in NP. NP-hard problems are those at least as hard as NP problems; i.e., all NP problems can be reduced (in polynomial time) to them. NP-hard problems need not be in NP; i.e., they need not have solutions verifiable in polynomial time. For instance, the Boolean satisfiability problem is NP-complete by the Cook–Levin theorem, so any instance of any problem in NP can be transformed mechanically into a Boolean satisfiability problem in polynomial time. The Boolean satisfiability problem is one of many NP-complete problems. If any NP-complete problem is in P, then it would follow that P = NP. However, many important problems are NP-complete, and no fast algorithm for any of them is known. From the definition alone it is unintuitive that NP-complete problems exist; however, a trivial NP-complete problem can be formulated as follows: given a Turing machine M guaranteed to halt in polynomial time, does a polynomial-size input that M will accept exist? It is in NP because (given an input) it is simple to check whether M accepts the input by simulating M; it is NP-complete because the verifier for any particular instance of a problem in NP can be encoded as a polynomial-time machine M that takes the solution to be verified as input. Then the question of whether the instance is a yes or no instance is determined by whether a valid input exists. The first natural problem proven to be NP-complete was the Boolean satisfiability problem, also known as SAT. As noted above, this is the Cook–Levin theorem; its proof that satisfiability is NP-complete contains technical details about Turing machines as they relate to the definition of NP. However, after this problem was proved to be NP-complete, proof by reduction provided a simpler way to show that many other problems are also NP-complete, including the game Sudoku discussed earlier. In this case, the proof shows that a solution of Sudoku in polynomial time could also be used to complete Latin squares in polynomial time. This in turn gives a solution to the problem of partitioning tri-partite graphs into triangles, which could then be used to find solutions for the special case of SAT known as 3-SAT, which then provides a solution for general Boolean satisfiability. So a polynomial-time solution to Sudoku leads, by a series of mechanical transformations, to a polynomial time solution of satisfiability, which in turn can be used to solve any other NP-problem in polynomial time. Using transformations like this, a vast class of seemingly unrelated problems are all reducible to one another, and are in a sense \"the same problem\". == Harder problems == Although it is unknown whether P = NP, problems outside of P are known. Just as the class P is defined in terms of polynomial running time, the class EXPTIME is the set of all decision problems that have exponential running time. In other words, any problem in EXPTIME is solvable by a deterministic Turing machine in O(2p(n)) time, where p(n) is a polynomial function of n. A decision problem is EXPTIME-complete if it is in EXPTIME, and every problem in EXPTIME has a polynomial-time many-one reduction to it. A number of problems are known to be EXPTIME-complete. Because it can be shown that P ≠ EXPTIME, these problems are outside P, and so require more than polynomial time. In fact, by the time hierarchy theorem, they cannot be solved in significantly less than exponential time. Examples include finding a perfect strategy for chess positions on an N × N board and similar problems for other board games. The problem of deciding the truth of a statement in Presburger arithmetic requires even more time. Fischer and Rabin proved in 1974 that every algorithm that decides the truth of Presburger statements of length n has a runtime of at least 2 2 c n {\\displaystyle 2^{2^{cn}}} for some constant c. Hence, the problem is known to need more than exponential run time. Even more difficult are the undecidable problems, such as the halting problem. They cannot be completely solved by any algorithm, in the sense that for any particular algorithm there is at least one input for which that algorithm will not produce the right answer; it will either produce the wrong answer, finish without giving a conclusive answer, or otherwise run forever without producing any answer at all. It is also possible to consider questions other than decision problems. One such class, consisting of counting problems, is called #P: whereas an NP problem asks \"Are there any solutions?\", the corresponding #P problem asks \"How many solutions are there?\". Clearly, a #P problem must be at least as hard as the corresponding NP problem, since a count of solutions immediately tells if at least one solution exists, if the count is greater than zero. Surprisingly, some #P problems that are believed to be difficult correspond to easy (for example linear-time) P problems. For these problems, it is very easy to tell whether solutions exist, but thought to be very hard to tell how many. Many of these problems are #P-complete, and hence among the hardest problems in #P, since a polynomial time solution to any of them would allow a polynomial time solution to all other #P problems. == Problems in NP not known to be in P or NP-complete == In 1975, Richard E. Ladner showed that if P ≠ NP, then there exist problems in NP that are neither in P nor NP-complete. Such problems are called NP-intermediate problems. The graph isomorphism problem, the discrete logarithm problem, and the integer factorization problem are examples of problems believed to be NP-intermediate. They are some of the very few NP problems not known to be in P or to be NP-complete. The graph isomorphism problem is the computational problem of determining whether two finite graphs are isomorphic. An important unsolved problem in complexity theory is whether the graph isomorphism problem is in P, NP-complete, or NP-intermediate. The answer is not known, but it is believed that the problem is at least not NP-complete. If graph isomorphism is NP-complete, the polynomial time hierarchy collapses to its second level. Since it is widely believed that the polynomial hierarchy does not collapse to any finite level, it is believed that graph isomorphism is not NP-complete. The best algorithm for this problem, due to László Babai, runs in quasi-polynomial time. The integer factorization problem is the computational problem of determining the prime factorization of a given integer. Phrased as a decision problem, it is the problem of deciding whether the input has a factor less than k. No efficient integer factorization algorithm is known, and this fact forms the basis of several modern cryptographic systems, such as the RSA algorithm. The integer factorization problem is in NP and in co-NP (and even in UP and co-UP). If the problem is NP-complete, the polynomial time hierarchy will collapse to its first level (i.e., NP = co-NP). The most efficient known algorithm for integer factorization is the general number field sieve, which takes expected time O ( exp ⁡ ( ( 64 n 9 log ⁡ ( 2 ) ) 1 3 ( log ⁡ ( n log ⁡ ( 2 ) ) ) 2 3 ) ) {\\displaystyle O\\left(\\exp \\left(\\left({\\tfrac {64n}{9}}\\log(2)\\right)^{\\frac {1}{3}}\\left(\\log(n\\log(2))\\right)^{\\frac {2}{3}}\\right)\\right)} to factor an n-bit integer. The best known quantum algorithm for this problem, Shor's algorithm, runs in polynomial time, although this does not indicate where the problem lies with respect to non-quantum complexity classes. == Does P mean \"easy\"? == All of the above discussion has assumed that P means \"easy\" and \"not in P\" means \"difficult\", an assumption known as Cobham's thesis. It is a common assumption in complexity theory; but there are caveats. First, it can be false in practice. A theoretical polynomial algorithm may have extremely large constant factors or exponents, rendering it impractical. For example, the problem of deciding whether a graph G contains H as a minor, where H is fixed, can be solved in a running time of O(n2), where n is the number of vertices in G. However, the big O notation hides a constant that depends superexponentially on H. The constant is greater than 2 ↑↑ ( 2 ↑↑ ( 2 ↑↑ ( h / 2 ) ) ) {\\displaystyle 2\\uparrow \\uparrow (2\\uparrow \\uparrow (2\\uparrow \\uparrow (h/2)))} (using Knuth's up-arrow notation), and where h is the number of vertices in H. On the other hand, even if a problem is shown to be NP-complete, and even if P ≠ NP, there may still be effective approaches to the problem in practice. There are algorithms for many NP-complete problems, such as the knapsack problem, the traveling salesman problem, and the Boolean satisfiability problem, that can solve to optimality many real-world instances in reasonable time. The empirical average-case complexity (time vs. problem size) of such algorithms can be surprisingly low. An example is the simplex algorithm in linear programming, which works surprisingly well in practice; despite having exponential worst-case time complexity, it runs on par with the best known polynomial-time algorithms. Finally, there are types of computations which do not conform to the Turing machine model on which P and NP are defined, such as quantum computation and randomized algorithms. == Reasons to believe P ≠ NP or P = NP == Cook provides a restatement of the problem in The P Versus NP Problem as \"Does P = NP?\" According to polls, most computer scientists believe that P ≠ NP. A key reason for this belief is that after decades of studying these problems no one has been able to find a polynomial-time algorithm for any of more than 3,000 important known NP-complete problems (see List of NP-complete problems). These algorithms were sought long before the concept of NP-completeness was even defined (Karp's 21 NP-complete problems, among the first found, were all well-known existing problems at the time they were shown to be NP-complete). Furthermore, the result P = NP would imply many other startling results that are currently believed to be false, such as NP = co-NP and P = PH. It is also intuitively argued that the existence of problems that are hard to solve but whose solutions are easy to verify matches real-world experience. If P = NP, then the world would be a profoundly different place than we usually assume it to be. There would be no special value in \"creative leaps\", no fundamental gap between solving a problem and recognizing the solution once it's found. On the other hand, some researchers believe that it is overconfident to believe P ≠ NP and that researchers should also explore proofs of P = NP. For example, in 2002 these statements were made: The main argument in favor of P ≠ NP is the total lack of fundamental progress in the area of exhaustive search. This is, in my opinion, a very weak argument. The space of algorithms is very large and we are only at the beginning of its exploration. [...] The resolution of Fermat's Last Theorem also shows that very simple questions may be settled only by very deep theories. Being attached to a speculation is not a good guide to research planning. One should always try both directions of every problem. Prejudice has caused famous mathematicians to fail to solve famous problems whose solution was opposite to their expectations, even though they had developed all the methods required. === DLIN vs NLIN === When one substitutes \"linear time on a multitape Turing machine\" for \"polynomial time\" in the definitions of P and NP, one obtains the classes DLIN and NLIN. It is known that DLIN ≠ NLIN. == Consequences of solution == One of the reasons the problem attracts so much attention is the consequences of the possible answers. Either direction of resolution would advance theory enormously, and perhaps have huge practical consequences as well. === P = NP === A proof that P = NP could have stunning practical consequences if the proof leads to efficient methods for solving some of the important problems in NP. The potential consequences, both positive and negative, arise since various NP-complete problems are fundamental in many fields. It is also very possible that a proof would not lead to practical algorithms for NP-complete problems. The formulation of the problem does not require that the bounding polynomial be small or even specifically known. A non-constructive proof might show a solution exists without specifying either an algorithm to obtain it or a specific bound. Even if the proof is constructive, showing an explicit bounding polynomial and algorithmic details, if the polynomial is not very low-order the algorithm might not be sufficiently efficient in practice. In this case the initial proof would be mainly of interest to theoreticians, but the knowledge that polynomial time solutions are possible would surely spur research into better (and possibly practical) methods to achieve them. A solution showing P = NP could upend the field of cryptography, which relies on certain problems being difficult. A constructive and efficient solution to an NP-complete problem such as 3-SAT would break most existing cryptosystems including: Existing implementations of public-key cryptography, a foundation for many modern security applications such as secure financial transactions over the Internet. Symmetric ciphers such as AES or 3DES, used for the encryption of communications data. Cryptographic hashing, which underlies blockchain cryptocurrencies such as Bitcoin, and is used to authenticate software updates. For these applications, finding a pre-image that hashes to a given value must be difficult, ideally taking exponential time. If P = NP, then this can take polynomial time, through reduction to SAT. These would need modification or replacement with information-theoretically secure solutions that do not assume P ≠ NP. There are also enormous benefits that would follow from rendering tractable many currently mathematically intractable problems. For instance, many problems in operations research are NP-complete, such as types of integer programming and the travelling salesman problem. Efficient solutions to these problems would have enormous implications for logistics. Many other important problems, such as some problems in protein structure prediction, are also NP-complete; making these problems efficiently solvable could considerably advance life sciences and biotechnology. These changes could be insignificant compared to the revolution that efficiently solving NP-complete problems would cause in mathematics itself. Gödel, in his early thoughts on computational complexity, noted that a mechanical method that could solve any problem would revolutionize mathematics: If there really were a machine with φ(n) ∼ k⋅n (or even ∼ k⋅n2), this would have consequences of the greatest importance. Namely, it would obviously mean that in spite of the undecidability of the Entscheidungsproblem, the mental work of a mathematician concerning Yes-or-No questions could be completely replaced by a machine. After all, one would simply have to choose the natural number n so large that when the machine does not deliver a result, it makes no sense to think more about the problem. Similarly, Stephen Cook (assuming not only a proof, but a practically efficient algorithm) says: ... it would transform mathematics by allowing a computer to find a formal proof of any theorem which has a proof of a reasonable length, since formal proofs can easily be recognized in polynomial time. Example problems may well include all of the CMI prize problems. Research mathematicians spend their careers trying to prove theorems, and some proofs have taken decades or even centuries to find after problems have been stated—for instance, Fermat's Last Theorem took over three centuries to prove. A method guaranteed to find a proof if a \"reasonable\" size proof exists, would essentially end this struggle. Donald Knuth has stated that he has come to believe that P = NP, but is reserved about the impact of a possible proof: [...] if you imagine a number M that's finite but incredibly large—like say the number 10↑↑↑↑3 discussed in my paper on \"coping with finiteness\"—then there's a humongous number of possible algorithms that do nM bitwise or addition or shift operations on n given bits, and it's really hard to believe that all of those algorithms fail. My main point, however, is that I don't believe that the equality P = NP will turn out to be helpful even if it is proved, because such a proof will almost surely be nonconstructive. === P ≠ NP === A proof of P ≠ NP would lack the practical computational benefits of a proof that P = NP, but would represent a great advance in computational complexity theory and guide future research. It would demonstrate that many common problems cannot be solved efficiently, so that the attention of researchers can be focused on partial solutions or solutions to other problems. Due to widespread belief in P ≠ NP, much of this focusing of research has already taken place. P ≠ NP still leaves open the average-case complexity of hard problems in NP. For example, it is possible that SAT requires exponential time in the worst case, but that almost all randomly selected instances of it are efficiently solvable. Russell Impagliazzo has described five hypothetical \"worlds\" that could result from different possible resolutions to the average-case complexity question. These range from \"Algorithmica\", where P = NP and problems like SAT can be solved efficiently in all instances, to \"Cryptomania\", where P ≠ NP and generating hard instances of problems outside P is easy, with three intermediate possibilities reflecting different possible distributions of difficulty over instances of NP-hard problems. The \"world\" where P ≠ NP but all problems in NP are tractable in the average case is called \"Heuristica\" in the paper. A Princeton University workshop in 2009 studied the status of the five worlds. == Results about difficulty of proof == Although the P = NP problem itself remains open despite a million-dollar prize and a huge amount of dedicated research, efforts to solve the problem have led to several new techniques. In particular, some of the most fruitful research related to the P = NP problem has been in showing that existing proof techniques are insufficient for answering the question, suggesting novel technical approaches are required. As additional evidence for the difficulty of the problem, essentially all known proof techniques in computational complexity theory fall into one of the following classifications, all insufficient to prove P ≠ NP: These barriers are another reason why NP-complete problems are useful: if a polynomial-time algorithm can be demonstrated for an NP-complete problem, this would solve the P = NP problem in a way not excluded by the above results. These barriers lead some computer scientists to suggest the P versus NP problem may be independent of standard axiom systems like ZFC (cannot be proved or disproved within them). An independence result could imply that either P ≠ NP and this is unprovable in (e.g.) ZFC, or that P = NP but it is unprovable in ZFC that any polynomial-time algorithms are correct. However, if the problem is undecidable even with much weaker assumptions extending the Peano axioms for integer arithmetic, then nearly polynomial-time algorithms exist for all NP problems. Therefore, assuming (as most complexity theorists do) some NP problems don't have efficient algorithms, proofs of independence with those techniques are impossible. This also implies proving independence from PA or ZFC with current techniques is no easier than proving all NP problems have efficient algorithms. == Logical characterizations == The P = NP problem can be restated as certain classes of logical statements, as a result of work in descriptive complexity. Consider all languages of finite structures with a fixed signature including a linear order relation. Then, all such languages in P are expressible in first-order logic with the addition of a suitable least fixed-point combinator. Recursive functions can be defined with this and the order relation. As long as the signature contains at least one predicate or function in addition to the distinguished order relation, so that the amount of space taken to store such finite structures is actually polynomial in the number of elements in the structure, this precisely characterizes P. Similarly, NP is the set of languages expressible in existential second-order logic—that is, second-order logic restricted to exclude universal quantification over relations, functions, and subsets. The languages in the polynomial hierarchy, PH, correspond to all of second-order logic. Thus, the question \"is P a proper subset of NP\" can be reformulated as \"is existential second-order logic able to describe languages (of finite linearly ordered structures with nontrivial signature) that first-order logic with least fixed point cannot?\". The word \"existential\" can even be dropped from the previous characterization, since P = NP if and only if P = PH (as the former would establish that NP = co-NP, which in turn implies that NP = PH). == Polynomial-time algorithms == No known algorithm for a NP-complete problem runs in polynomial time. However, there are algorithms known for NP-complete problems that if P = NP, the algorithm runs in polynomial time on accepting instances (although with enormous constants, making the algorithm impractical). However, these algorithms do not qualify as polynomial time because their running time on rejecting instances are not polynomial. The following algorithm, due to Levin (without any citation), is such an example below. It correctly accepts the NP-complete language SUBSET-SUM. It runs in polynomial time on inputs that are in SUBSET-SUM if and only if P = NP: // Algorithm that accepts the NP-complete language SUBSET-SUM. // // this is a polynomial-time algorithm if and only if P = NP. // // \"Polynomial-time\" means it returns \"yes\" in polynomial time when // the answer should be \"yes\", and runs forever when it is \"no\". // // Input: S = a finite set of integers // Output: \"yes\" if any subset of S adds up to 0. // Runs forever with no output otherwise. // Note: \"Program number M\" is the program obtained by // writing the integer M in binary, then // considering that string of bits to be a // program. Every possible program can be // generated this way, though most do nothing // because of syntax errors. FOR K = 1...∞ FOR M = 1...K Run program number M for K steps with input S IF the program outputs a list of distinct integers AND the integers are all in S AND the integers sum to 0 THEN OUTPUT \"yes\" and HALT This is a polynomial-time algorithm accepting an NP-complete language only if P = NP. \"Accepting\" means it gives \"yes\" answers in polynomial time, but is allowed to run forever when the answer is \"no\" (also known as a semi-algorithm). This algorithm is enormously impractical, even if P = NP. If the shortest program that can solve SUBSET-SUM in polynomial time is b bits long, the above algorithm will try at least 2b − 1 other programs first. == Formal definitions == === P and NP === A decision problem is a problem that takes as input some string w over an alphabet Σ, and outputs \"yes\" or \"no\". If there is an algorithm (say a Turing machine, or a computer program with unbounded memory) that produces the correct answer for any input string of length n in at most cnk steps, where k and c are constants independent of the input string, then we say that the problem can be solved in polynomial time and we place it in the class P. Formally, P is the set of languages that can be decided by a deterministic polynomial-time Turing machine. Meaning, P = { L : L = L ( M ) for some deterministic polynomial-time Turing machine M } {\\displaystyle {\\mathsf {P}}=\\{L:L=L(M){\\text{ for some deterministic polynomial-time Turing machine }}M\\}} where L ( M ) = { w ∈ Σ ∗ : M accepts w } {\\displaystyle L(M)=\\{w\\in \\Sigma ^{*}:M{\\text{ accepts }}w\\}} and a deterministic polynomial-time Turing machine is a deterministic Turing machine M that satisfies two conditions: M halts on all inputs w and there exists k ∈ N {\\displaystyle k\\in N} such that T M ( n ) ∈ O ( n k ) {\\displaystyle T_{M}(n)\\in O(n^{k})} , where O refers to the big O notation and T M ( n ) = max { t M ( w ) : w ∈ Σ ∗ , | w | = n } {\\displaystyle T_{M}(n)=\\max\\{t_{M}(w):w\\in \\Sigma ^{*},|w|=n\\}} t M ( w ) = number of steps M takes to halt on input w . {\\displaystyle t_{M}(w)={\\text{ number of steps }}M{\\text{ takes to halt on input }}w.} NP can be defined similarly using nondeterministic Turing machines (the traditional way). However, a modern approach uses the concept of certificate and verifier. Formally, NP is the set of languages with a finite alphabet and verifier that runs in polynomial time. The following defines a \"verifier\": Let L be a language over a finite alphabet, Σ. L ∈ NP if, and only if, there exists a binary relation R ⊂ Σ ∗ × Σ ∗ {\\displaystyle R\\subset \\Sigma ^{*}\\times \\Sigma ^{*}} and a positive integer k such that the following two conditions are satisfied: For all x ∈ Σ ∗ {\\displaystyle x\\in \\Sigma ^{*}} , x ∈ L ⇔ ∃ y ∈ Σ ∗ {\\displaystyle x\\in L\\Leftrightarrow \\exists y\\in \\Sigma ^{*}} such that (x, y) ∈ R and | y | ∈ O ( | x | k ) {\\displaystyle |y|\\in O(|x|^{k})} ; and the language L R = { x # y : ( x , y ) ∈ R } {\\displaystyle L_{R}=\\{x\\#y:(x,y)\\in R\\}} over Σ ∪ { # } {\\displaystyle \\Sigma \\cup \\{\\#\\}} is decidable by a deterministic Turing machine in polynomial time. A Turing machine that decides LR is called a verifier for L and a y such that (x, y) ∈ R is called a certificate of membership of x in L. Not all verifiers must be polynomial-time. However, for L to be in NP, there must be a verifier that runs in polynomial time. ==== Example ==== Let C O M P O S I T E = { x ∈ N ∣ x = p q for integers p , q > 1 } {\\displaystyle \\mathrm {COMPOSITE} =\\left\\{x\\in \\mathbb {N} \\mid x=pq{\\text{ for integers }}p,q>1\\right\\}} R = { ( x , y ) ∈ N × N ∣ 1 < y ≤ x and y divides x } . {\\displaystyle R=\\left\\{(x,y)\\in \\mathbb {N} \\times \\mathbb {N} \\mid 1"
  },
  "chunks": [
    {
      "id": "pversusnpproblem_8c43e776_c0000",
      "article_id": "pversusnpproblem_8c43e776",
      "section": "Lead",
      "heading_path": "Lead",
      "start_char": 0,
      "end_char": 956,
      "content": "The P versus NP problem is a major unsolved problem in theoretical computer science. Informally, it asks whether every problem whose solution can be quickly verified can also be quickly solved. Here, \"quickly\" means an algorithm exists that solves the task and runs in polynomial time (as opposed to, say, exponential time), meaning the task completion time is bounded above by a polynomial function on the size of the input to the algorithm. The general class of questions that some algorithm can answer in polynomial time is \"P\" or \"class P\". For some questions, there is no known way to find an answer quickly, but if provided with an answer, it can be verified quickly. The class of questions where an answer can be verified in polynomial time is \"NP\", standing for \"nondeterministic polynomial time\". An answer to the P versus NP question would determine whether problems that can be verified in polynomial time can also be solved in polynomial time.",
      "char_count": 955,
      "token_estimate": 238,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "pversusnpproblem_8c43e776_c0001",
      "article_id": "pversusnpproblem_8c43e776",
      "section": "Lead",
      "heading_path": "Lead",
      "start_char": 956,
      "end_char": 1698,
      "content": "If P ≠ NP, which is widely believed, it would mean that there are problems in NP that are harder to compute than to verify: they could not be solved in polynomial time, but the answer could be verified in polynomial time. The problem has been called the most important open problem in computer science. Aside from being an important problem in computational theory, a proof either way would have profound implications for mathematics, cryptography, algorithm research, artificial intelligence, game theory, multimedia processing, philosophy, economics and many other fields. It is one of the seven Millennium Prize Problems selected by the Clay Mathematics Institute, each of which carries a US$1,000,000 prize for the first correct solution.",
      "char_count": 742,
      "token_estimate": 185,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "pversusnpproblem_8c43e776_c0002",
      "article_id": "pversusnpproblem_8c43e776",
      "section": "== Example ==",
      "heading_path": "== Example ==",
      "start_char": 1712,
      "end_char": 2576,
      "content": "== Example == Consider the following yes/no problem: given an incomplete Sudoku grid of size n 2 × n 2 {\\displaystyle n^{2}\\times n^{2}} , is there at least one legal solution where every row, column, and n × n {\\displaystyle n\\times n} square contains the integers 1 through n 2 {\\displaystyle n^{2}} ? It is straightforward to verify \"yes\" instances of this generalized Sudoku problem given a candidate solution. However, it is not known whether there is a polynomial-time algorithm that can correctly answer \"yes\" or \"no\" to all instances of this problem. Therefore, generalized Sudoku is in NP (quickly verifiable), but may or may not be in P (quickly solvable). (It is necessary to consider a generalized version of Sudoku, as any fixed size Sudoku has only a finite number of possible grids. In this case the problem is in P, as the answer can be found by table lookup.)",
      "char_count": 876,
      "token_estimate": 219,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "pversusnpproblem_8c43e776_c0003",
      "article_id": "pversusnpproblem_8c43e776",
      "section": "== History ==",
      "heading_path": "== History ==",
      "start_char": 2589,
      "end_char": 3446,
      "content": "== History == The precise statement of the P versus NP problem was introduced in 1971 by Stephen Cook in his seminal paper \"The complexity of theorem proving procedures\" (and independently by Leonid Levin in 1973). Although the P versus NP problem was formally defined in 1971, there were previous inklings of the problems involved, the difficulty of proof, and the potential consequences. In 1955, mathematician John Nash wrote a letter to the National Security Agency, speculating that the time required to crack a sufficiently complex code would increase exponentially with the length of the key. If proved (and Nash was suitably skeptical), this would imply what is now called P ≠ NP, since a proposed key can be verified in polynomial time. Another mention of the underlying problem occurred in a 1956 letter written by Kurt Gödel to John von Neumann.",
      "char_count": 856,
      "token_estimate": 214,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "pversusnpproblem_8c43e776_c0004",
      "article_id": "pversusnpproblem_8c43e776",
      "section": "== History ==",
      "heading_path": "== History ==",
      "start_char": 3446,
      "end_char": 3688,
      "content": "Gödel asked whether theorem-proving (now known to be co-NP-complete) could be solved in quadratic or linear time, and pointed out one of the most important consequences—that if so, then the discovery of mathematical proofs could be automated.",
      "char_count": 242,
      "token_estimate": 60,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "pversusnpproblem_8c43e776_c0005",
      "article_id": "pversusnpproblem_8c43e776",
      "section": "== Context ==",
      "heading_path": "== Context ==",
      "start_char": 3689,
      "end_char": 4384,
      "content": "== Context == The relation between the complexity classes P and NP is studied in computational complexity theory, the part of the theory of computation dealing with the resources required during computation to solve a given problem. The most common resources are time (how many steps it takes to solve a problem) and space (how much memory it takes to solve a problem). In such analysis, a model of the computer for which time must be analyzed is required. Typically such models assume that the computer is deterministic (given the computer's present state and any inputs, there is only one possible action that the computer might take) and sequential (it performs actions one after the other).",
      "char_count": 694,
      "token_estimate": 173,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "pversusnpproblem_8c43e776_c0006",
      "article_id": "pversusnpproblem_8c43e776",
      "section": "== Context ==",
      "heading_path": "== Context ==",
      "start_char": 4384,
      "end_char": 5245,
      "content": "In this theory, the class P consists of all decision problems (defined below) solvable on a deterministic sequential machine in a duration polynomial in the size of the input; the class NP consists of all decision problems whose positive solutions are verifiable in polynomial time given the right information, or equivalently, whose solution can be found in polynomial time on a non-deterministic machine. Clearly, P ⊆ NP. Arguably, the biggest open question in theoretical computer science concerns the relationship between those two classes: Is P equal to NP? Since 2002, William Gasarch has conducted three polls of researchers concerning this and related questions. Confidence that P ≠ NP has been increasing – in 2019, 88% believed P ≠ NP, as opposed to 83% in 2012 and 61% in 2002. When restricted to experts, the 2019 answers became 99% believed P ≠ NP.",
      "char_count": 861,
      "token_estimate": 215,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "pversusnpproblem_8c43e776_c0007",
      "article_id": "pversusnpproblem_8c43e776",
      "section": "== Context ==",
      "heading_path": "== Context ==",
      "start_char": 5246,
      "end_char": 5482,
      "content": "These polls do not imply whether P = NP, Gasarch himself stated: \"This does not bring us any closer to solving P=?NP or to knowing when it will be solved, but it attempts to be an objective report on the subjective opinion of this era.\"",
      "char_count": 236,
      "token_estimate": 59,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "pversusnpproblem_8c43e776_c0008",
      "article_id": "pversusnpproblem_8c43e776",
      "section": "== NP-completeness ==",
      "heading_path": "== NP-completeness ==",
      "start_char": 5491,
      "end_char": 6445,
      "content": "== NP-completeness == To attack the P = NP question, the concept of NP-completeness is very useful. NP-complete problems are problems that any other NP problem is reducible to in polynomial time and whose solution is still verifiable in polynomial time. That is, any NP problem can be transformed into any NP-complete problem. Informally, an NP-complete problem is an NP problem that is at least as \"tough\" as any other problem in NP. NP-hard problems are those at least as hard as NP problems; i.e., all NP problems can be reduced (in polynomial time) to them. NP-hard problems need not be in NP; i.e., they need not have solutions verifiable in polynomial time. For instance, the Boolean satisfiability problem is NP-complete by the Cook–Levin theorem, so any instance of any problem in NP can be transformed mechanically into a Boolean satisfiability problem in polynomial time. The Boolean satisfiability problem is one of many NP-complete problems.",
      "char_count": 953,
      "token_estimate": 238,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "pversusnpproblem_8c43e776_c0009",
      "article_id": "pversusnpproblem_8c43e776",
      "section": "== NP-completeness ==",
      "heading_path": "== NP-completeness ==",
      "start_char": 6445,
      "end_char": 7385,
      "content": "If any NP-complete problem is in P, then it would follow that P = NP. However, many important problems are NP-complete, and no fast algorithm for any of them is known. From the definition alone it is unintuitive that NP-complete problems exist; however, a trivial NP-complete problem can be formulated as follows: given a Turing machine M guaranteed to halt in polynomial time, does a polynomial-size input that M will accept exist? It is in NP because (given an input) it is simple to check whether M accepts the input by simulating M; it is NP-complete because the verifier for any particular instance of a problem in NP can be encoded as a polynomial-time machine M that takes the solution to be verified as input. Then the question of whether the instance is a yes or no instance is determined by whether a valid input exists. The first natural problem proven to be NP-complete was the Boolean satisfiability problem, also known as SAT.",
      "char_count": 940,
      "token_estimate": 235,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "pversusnpproblem_8c43e776_c0010",
      "article_id": "pversusnpproblem_8c43e776",
      "section": "== NP-completeness ==",
      "heading_path": "== NP-completeness ==",
      "start_char": 7386,
      "end_char": 8372,
      "content": "As noted above, this is the Cook–Levin theorem; its proof that satisfiability is NP-complete contains technical details about Turing machines as they relate to the definition of NP. However, after this problem was proved to be NP-complete, proof by reduction provided a simpler way to show that many other problems are also NP-complete, including the game Sudoku discussed earlier. In this case, the proof shows that a solution of Sudoku in polynomial time could also be used to complete Latin squares in polynomial time. This in turn gives a solution to the problem of partitioning tri-partite graphs into triangles, which could then be used to find solutions for the special case of SAT known as 3-SAT, which then provides a solution for general Boolean satisfiability. So a polynomial-time solution to Sudoku leads, by a series of mechanical transformations, to a polynomial time solution of satisfiability, which in turn can be used to solve any other NP-problem in polynomial time.",
      "char_count": 986,
      "token_estimate": 246,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "pversusnpproblem_8c43e776_c0011",
      "article_id": "pversusnpproblem_8c43e776",
      "section": "== NP-completeness ==",
      "heading_path": "== NP-completeness ==",
      "start_char": 8373,
      "end_char": 8523,
      "content": "Using transformations like this, a vast class of seemingly unrelated problems are all reducible to one another, and are in a sense \"the same problem\".",
      "char_count": 150,
      "token_estimate": 37,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "pversusnpproblem_8c43e776_c0012",
      "article_id": "pversusnpproblem_8c43e776",
      "section": "== Harder problems ==",
      "heading_path": "== Harder problems ==",
      "start_char": 8524,
      "end_char": 9460,
      "content": "== Harder problems == Although it is unknown whether P = NP, problems outside of P are known. Just as the class P is defined in terms of polynomial running time, the class EXPTIME is the set of all decision problems that have exponential running time. In other words, any problem in EXPTIME is solvable by a deterministic Turing machine in O(2p(n)) time, where p(n) is a polynomial function of n. A decision problem is EXPTIME-complete if it is in EXPTIME, and every problem in EXPTIME has a polynomial-time many-one reduction to it. A number of problems are known to be EXPTIME-complete. Because it can be shown that P ≠ EXPTIME, these problems are outside P, and so require more than polynomial time. In fact, by the time hierarchy theorem, they cannot be solved in significantly less than exponential time. Examples include finding a perfect strategy for chess positions on an N × N board and similar problems for other board games.",
      "char_count": 935,
      "token_estimate": 233,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "pversusnpproblem_8c43e776_c0013",
      "article_id": "pversusnpproblem_8c43e776",
      "section": "== Harder problems ==",
      "heading_path": "== Harder problems ==",
      "start_char": 9460,
      "end_char": 10305,
      "content": "The problem of deciding the truth of a statement in Presburger arithmetic requires even more time. Fischer and Rabin proved in 1974 that every algorithm that decides the truth of Presburger statements of length n has a runtime of at least 2 2 c n {\\displaystyle 2^{2^{cn}}} for some constant c. Hence, the problem is known to need more than exponential run time. Even more difficult are the undecidable problems, such as the halting problem. They cannot be completely solved by any algorithm, in the sense that for any particular algorithm there is at least one input for which that algorithm will not produce the right answer; it will either produce the wrong answer, finish without giving a conclusive answer, or otherwise run forever without producing any answer at all. It is also possible to consider questions other than decision problems.",
      "char_count": 845,
      "token_estimate": 211,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "pversusnpproblem_8c43e776_c0014",
      "article_id": "pversusnpproblem_8c43e776",
      "section": "== Harder problems ==",
      "heading_path": "== Harder problems ==",
      "start_char": 10306,
      "end_char": 11117,
      "content": "One such class, consisting of counting problems, is called #P: whereas an NP problem asks \"Are there any solutions?\", the corresponding #P problem asks \"How many solutions are there?\". Clearly, a #P problem must be at least as hard as the corresponding NP problem, since a count of solutions immediately tells if at least one solution exists, if the count is greater than zero. Surprisingly, some #P problems that are believed to be difficult correspond to easy (for example linear-time) P problems. For these problems, it is very easy to tell whether solutions exist, but thought to be very hard to tell how many. Many of these problems are #P-complete, and hence among the hardest problems in #P, since a polynomial time solution to any of them would allow a polynomial time solution to all other #P problems.",
      "char_count": 811,
      "token_estimate": 202,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "pversusnpproblem_8c43e776_c0015",
      "article_id": "pversusnpproblem_8c43e776",
      "section": "== Problems in NP not known to be in P or NP-complete ==",
      "heading_path": "== Problems in NP not known to be in P or NP-complete ==",
      "start_char": 11153,
      "end_char": 12063,
      "content": "== Problems in NP not known to be in P or NP-complete == In 1975, Richard E. Ladner showed that if P ≠ NP, then there exist problems in NP that are neither in P nor NP-complete. Such problems are called NP-intermediate problems. The graph isomorphism problem, the discrete logarithm problem, and the integer factorization problem are examples of problems believed to be NP-intermediate. They are some of the very few NP problems not known to be in P or to be NP-complete. The graph isomorphism problem is the computational problem of determining whether two finite graphs are isomorphic. An important unsolved problem in complexity theory is whether the graph isomorphism problem is in P, NP-complete, or NP-intermediate. The answer is not known, but it is believed that the problem is at least not NP-complete. If graph isomorphism is NP-complete, the polynomial time hierarchy collapses to its second level.",
      "char_count": 909,
      "token_estimate": 227,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "pversusnpproblem_8c43e776_c0016",
      "article_id": "pversusnpproblem_8c43e776",
      "section": "== Problems in NP not known to be in P or NP-complete ==",
      "heading_path": "== Problems in NP not known to be in P or NP-complete ==",
      "start_char": 12063,
      "end_char": 12884,
      "content": "Since it is widely believed that the polynomial hierarchy does not collapse to any finite level, it is believed that graph isomorphism is not NP-complete. The best algorithm for this problem, due to László Babai, runs in quasi-polynomial time. The integer factorization problem is the computational problem of determining the prime factorization of a given integer. Phrased as a decision problem, it is the problem of deciding whether the input has a factor less than k. No efficient integer factorization algorithm is known, and this fact forms the basis of several modern cryptographic systems, such as the RSA algorithm. The integer factorization problem is in NP and in co-NP (and even in UP and co-UP). If the problem is NP-complete, the polynomial time hierarchy will collapse to its first level (i.e., NP = co-NP).",
      "char_count": 821,
      "token_estimate": 205,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "pversusnpproblem_8c43e776_c0017",
      "article_id": "pversusnpproblem_8c43e776",
      "section": "== Problems in NP not known to be in P or NP-complete ==",
      "heading_path": "== Problems in NP not known to be in P or NP-complete ==",
      "start_char": 12885,
      "end_char": 13449,
      "content": "The most efficient known algorithm for integer factorization is the general number field sieve, which takes expected time O ( exp ⁡ ( ( 64 n 9 log ⁡ ( 2 ) ) 1 3 ( log ⁡ ( n log ⁡ ( 2 ) ) ) 2 3 ) ) {\\displaystyle O\\left(\\exp \\left(\\left({\\tfrac {64n}{9}}\\log(2)\\right)^{\\frac {1}{3}}\\left(\\log(n\\log(2))\\right)^{\\frac {2}{3}}\\right)\\right)} to factor an n-bit integer. The best known quantum algorithm for this problem, Shor's algorithm, runs in polynomial time, although this does not indicate where the problem lies with respect to non-quantum complexity classes.",
      "char_count": 564,
      "token_estimate": 141,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "pversusnpproblem_8c43e776_c0018",
      "article_id": "pversusnpproblem_8c43e776",
      "section": "== Does P mean \"easy\"? ==",
      "heading_path": "== Does P mean \"easy\"? ==",
      "start_char": 13419,
      "end_char": 14288,
      "content": "== Does P mean \"easy\"? == All of the above discussion has assumed that P means \"easy\" and \"not in P\" means \"difficult\", an assumption known as Cobham's thesis. It is a common assumption in complexity theory; but there are caveats. First, it can be false in practice. A theoretical polynomial algorithm may have extremely large constant factors or exponents, rendering it impractical. For example, the problem of deciding whether a graph G contains H as a minor, where H is fixed, can be solved in a running time of O(n2), where n is the number of vertices in G. However, the big O notation hides a constant that depends superexponentially on H. The constant is greater than 2 ↑↑ ( 2 ↑↑ ( 2 ↑↑ ( h / 2 ) ) ) {\\displaystyle 2\\uparrow \\uparrow (2\\uparrow \\uparrow (2\\uparrow \\uparrow (h/2)))} (using Knuth's up-arrow notation), and where h is the number of vertices in H.",
      "char_count": 868,
      "token_estimate": 217,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "pversusnpproblem_8c43e776_c0019",
      "article_id": "pversusnpproblem_8c43e776",
      "section": "== Does P mean \"easy\"? ==",
      "heading_path": "== Does P mean \"easy\"? ==",
      "start_char": 14288,
      "end_char": 15171,
      "content": "On the other hand, even if a problem is shown to be NP-complete, and even if P ≠ NP, there may still be effective approaches to the problem in practice. There are algorithms for many NP-complete problems, such as the knapsack problem, the traveling salesman problem, and the Boolean satisfiability problem, that can solve to optimality many real-world instances in reasonable time. The empirical average-case complexity (time vs. problem size) of such algorithms can be surprisingly low. An example is the simplex algorithm in linear programming, which works surprisingly well in practice; despite having exponential worst-case time complexity, it runs on par with the best known polynomial-time algorithms. Finally, there are types of computations which do not conform to the Turing machine model on which P and NP are defined, such as quantum computation and randomized algorithms.",
      "char_count": 883,
      "token_estimate": 220,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "pversusnpproblem_8c43e776_c0020",
      "article_id": "pversusnpproblem_8c43e776",
      "section": "== Reasons to believe P ≠ NP or P = NP ==",
      "heading_path": "== Reasons to believe P ≠ NP or P = NP ==",
      "start_char": 15188,
      "end_char": 15994,
      "content": "== Reasons to believe P ≠ NP or P = NP == Cook provides a restatement of the problem in The P Versus NP Problem as \"Does P = NP?\" According to polls, most computer scientists believe that P ≠ NP. A key reason for this belief is that after decades of studying these problems no one has been able to find a polynomial-time algorithm for any of more than 3,000 important known NP-complete problems (see List of NP-complete problems). These algorithms were sought long before the concept of NP-completeness was even defined (Karp's 21 NP-complete problems, among the first found, were all well-known existing problems at the time they were shown to be NP-complete). Furthermore, the result P = NP would imply many other startling results that are currently believed to be false, such as NP = co-NP and P = PH.",
      "char_count": 805,
      "token_estimate": 201,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "pversusnpproblem_8c43e776_c0021",
      "article_id": "pversusnpproblem_8c43e776",
      "section": "== Reasons to believe P ≠ NP or P = NP ==",
      "heading_path": "== Reasons to believe P ≠ NP or P = NP ==",
      "start_char": 15994,
      "end_char": 16960,
      "content": "It is also intuitively argued that the existence of problems that are hard to solve but whose solutions are easy to verify matches real-world experience. If P = NP, then the world would be a profoundly different place than we usually assume it to be. There would be no special value in \"creative leaps\", no fundamental gap between solving a problem and recognizing the solution once it's found. On the other hand, some researchers believe that it is overconfident to believe P ≠ NP and that researchers should also explore proofs of P = NP. For example, in 2002 these statements were made: The main argument in favor of P ≠ NP is the total lack of fundamental progress in the area of exhaustive search. This is, in my opinion, a very weak argument. The space of algorithms is very large and we are only at the beginning of its exploration. [...] The resolution of Fermat's Last Theorem also shows that very simple questions may be settled only by very deep theories.",
      "char_count": 966,
      "token_estimate": 241,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "pversusnpproblem_8c43e776_c0022",
      "article_id": "pversusnpproblem_8c43e776",
      "section": "== Reasons to believe P ≠ NP or P = NP ==",
      "heading_path": "== Reasons to believe P ≠ NP or P = NP ==",
      "start_char": 16961,
      "end_char": 17274,
      "content": "Being attached to a speculation is not a good guide to research planning. One should always try both directions of every problem. Prejudice has caused famous mathematicians to fail to solve famous problems whose solution was opposite to their expectations, even though they had developed all the methods required.",
      "char_count": 313,
      "token_estimate": 78,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "pversusnpproblem_8c43e776_c0023",
      "article_id": "pversusnpproblem_8c43e776",
      "section": "== = DLIN vs NLIN ==",
      "heading_path": "== = DLIN vs NLIN ==",
      "start_char": 17254,
      "end_char": 17444,
      "content": "== = DLIN vs NLIN === When one substitutes \"linear time on a multitape Turing machine\" for \"polynomial time\" in the definitions of P and NP, one obtains the classes DLIN and NLIN. It is known that DLIN ≠ NLIN.",
      "char_count": 209,
      "token_estimate": 52,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "pversusnpproblem_8c43e776_c0024",
      "article_id": "pversusnpproblem_8c43e776",
      "section": "== Consequences of solution ==",
      "heading_path": "== Consequences of solution ==",
      "start_char": 17474,
      "end_char": 17696,
      "content": "== Consequences of solution == One of the reasons the problem attracts so much attention is the consequences of the possible answers. Either direction of resolution would advance theory enormously, and perhaps have huge practical consequences as well.",
      "char_count": 251,
      "token_estimate": 62,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "pversusnpproblem_8c43e776_c0025",
      "article_id": "pversusnpproblem_8c43e776",
      "section": "== = P = NP ==",
      "heading_path": "== = P = NP ==",
      "start_char": 17710,
      "end_char": 18555,
      "content": "== = P = NP === A proof that P = NP could have stunning practical consequences if the proof leads to efficient methods for solving some of the important problems in NP. The potential consequences, both positive and negative, arise since various NP-complete problems are fundamental in many fields. It is also very possible that a proof would not lead to practical algorithms for NP-complete problems. The formulation of the problem does not require that the bounding polynomial be small or even specifically known. A non-constructive proof might show a solution exists without specifying either an algorithm to obtain it or a specific bound. Even if the proof is constructive, showing an explicit bounding polynomial and algorithmic details, if the polynomial is not very low-order the algorithm might not be sufficiently efficient in practice.",
      "char_count": 844,
      "token_estimate": 211,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "pversusnpproblem_8c43e776_c0026",
      "article_id": "pversusnpproblem_8c43e776",
      "section": "== = P = NP ==",
      "heading_path": "== = P = NP ==",
      "start_char": 18555,
      "end_char": 19529,
      "content": "In this case the initial proof would be mainly of interest to theoreticians, but the knowledge that polynomial time solutions are possible would surely spur research into better (and possibly practical) methods to achieve them. A solution showing P = NP could upend the field of cryptography, which relies on certain problems being difficult. A constructive and efficient solution to an NP-complete problem such as 3-SAT would break most existing cryptosystems including: Existing implementations of public-key cryptography, a foundation for many modern security applications such as secure financial transactions over the Internet. Symmetric ciphers such as AES or 3DES, used for the encryption of communications data. Cryptographic hashing, which underlies blockchain cryptocurrencies such as Bitcoin, and is used to authenticate software updates. For these applications, finding a pre-image that hashes to a given value must be difficult, ideally taking exponential time.",
      "char_count": 974,
      "token_estimate": 243,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "pversusnpproblem_8c43e776_c0027",
      "article_id": "pversusnpproblem_8c43e776",
      "section": "== = P = NP ==",
      "heading_path": "== = P = NP ==",
      "start_char": 19530,
      "end_char": 20434,
      "content": "If P = NP, then this can take polynomial time, through reduction to SAT. These would need modification or replacement with information-theoretically secure solutions that do not assume P ≠ NP. There are also enormous benefits that would follow from rendering tractable many currently mathematically intractable problems. For instance, many problems in operations research are NP-complete, such as types of integer programming and the travelling salesman problem. Efficient solutions to these problems would have enormous implications for logistics. Many other important problems, such as some problems in protein structure prediction, are also NP-complete; making these problems efficiently solvable could considerably advance life sciences and biotechnology. These changes could be insignificant compared to the revolution that efficiently solving NP-complete problems would cause in mathematics itself.",
      "char_count": 904,
      "token_estimate": 226,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "pversusnpproblem_8c43e776_c0028",
      "article_id": "pversusnpproblem_8c43e776",
      "section": "== = P = NP ==",
      "heading_path": "== = P = NP ==",
      "start_char": 20435,
      "end_char": 21386,
      "content": "Gödel, in his early thoughts on computational complexity, noted that a mechanical method that could solve any problem would revolutionize mathematics: If there really were a machine with φ(n) ∼ k⋅n (or even ∼ k⋅n2), this would have consequences of the greatest importance. Namely, it would obviously mean that in spite of the undecidability of the Entscheidungsproblem, the mental work of a mathematician concerning Yes-or-No questions could be completely replaced by a machine. After all, one would simply have to choose the natural number n so large that when the machine does not deliver a result, it makes no sense to think more about the problem. Similarly, Stephen Cook (assuming not only a proof, but a practically efficient algorithm) says: ... it would transform mathematics by allowing a computer to find a formal proof of any theorem which has a proof of a reasonable length, since formal proofs can easily be recognized in polynomial time.",
      "char_count": 951,
      "token_estimate": 237,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "pversusnpproblem_8c43e776_c0029",
      "article_id": "pversusnpproblem_8c43e776",
      "section": "== = P = NP ==",
      "heading_path": "== = P = NP ==",
      "start_char": 21387,
      "end_char": 22250,
      "content": "Example problems may well include all of the CMI prize problems. Research mathematicians spend their careers trying to prove theorems, and some proofs have taken decades or even centuries to find after problems have been stated—for instance, Fermat's Last Theorem took over three centuries to prove. A method guaranteed to find a proof if a \"reasonable\" size proof exists, would essentially end this struggle. Donald Knuth has stated that he has come to believe that P = NP, but is reserved about the impact of a possible proof: [...] if you imagine a number M that's finite but incredibly large—like say the number 10↑↑↑↑3 discussed in my paper on \"coping with finiteness\"—then there's a humongous number of possible algorithms that do nM bitwise or addition or shift operations on n given bits, and it's really hard to believe that all of those algorithms fail.",
      "char_count": 863,
      "token_estimate": 215,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "pversusnpproblem_8c43e776_c0030",
      "article_id": "pversusnpproblem_8c43e776",
      "section": "== = P = NP ==",
      "heading_path": "== = P = NP ==",
      "start_char": 22251,
      "end_char": 22433,
      "content": "My main point, however, is that I don't believe that the equality P = NP will turn out to be helpful even if it is proved, because such a proof will almost surely be nonconstructive.",
      "char_count": 182,
      "token_estimate": 45,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "pversusnpproblem_8c43e776_c0031",
      "article_id": "pversusnpproblem_8c43e776",
      "section": "== = P ≠ NP ==",
      "heading_path": "== = P ≠ NP ==",
      "start_char": 22434,
      "end_char": 23310,
      "content": "== = P ≠ NP === A proof of P ≠ NP would lack the practical computational benefits of a proof that P = NP, but would represent a great advance in computational complexity theory and guide future research. It would demonstrate that many common problems cannot be solved efficiently, so that the attention of researchers can be focused on partial solutions or solutions to other problems. Due to widespread belief in P ≠ NP, much of this focusing of research has already taken place. P ≠ NP still leaves open the average-case complexity of hard problems in NP. For example, it is possible that SAT requires exponential time in the worst case, but that almost all randomly selected instances of it are efficiently solvable. Russell Impagliazzo has described five hypothetical \"worlds\" that could result from different possible resolutions to the average-case complexity question.",
      "char_count": 875,
      "token_estimate": 218,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "pversusnpproblem_8c43e776_c0032",
      "article_id": "pversusnpproblem_8c43e776",
      "section": "== = P ≠ NP ==",
      "heading_path": "== = P ≠ NP ==",
      "start_char": 23310,
      "end_char": 23843,
      "content": "These range from \"Algorithmica\", where P = NP and problems like SAT can be solved efficiently in all instances, to \"Cryptomania\", where P ≠ NP and generating hard instances of problems outside P is easy, with three intermediate possibilities reflecting different possible distributions of difficulty over instances of NP-hard problems. The \"world\" where P ≠ NP but all problems in NP are tractable in the average case is called \"Heuristica\" in the paper. A Princeton University workshop in 2009 studied the status of the five worlds.",
      "char_count": 533,
      "token_estimate": 133,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "pversusnpproblem_8c43e776_c0033",
      "article_id": "pversusnpproblem_8c43e776",
      "section": "== Results about difficulty of proof ==",
      "heading_path": "== Results about difficulty of proof ==",
      "start_char": 23869,
      "end_char": 24766,
      "content": "== Results about difficulty of proof == Although the P = NP problem itself remains open despite a million-dollar prize and a huge amount of dedicated research, efforts to solve the problem have led to several new techniques. In particular, some of the most fruitful research related to the P = NP problem has been in showing that existing proof techniques are insufficient for answering the question, suggesting novel technical approaches are required. As additional evidence for the difficulty of the problem, essentially all known proof techniques in computational complexity theory fall into one of the following classifications, all insufficient to prove P ≠ NP: These barriers are another reason why NP-complete problems are useful: if a polynomial-time algorithm can be demonstrated for an NP-complete problem, this would solve the P = NP problem in a way not excluded by the above results.",
      "char_count": 896,
      "token_estimate": 224,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "pversusnpproblem_8c43e776_c0034",
      "article_id": "pversusnpproblem_8c43e776",
      "section": "== Results about difficulty of proof ==",
      "heading_path": "== Results about difficulty of proof ==",
      "start_char": 24766,
      "end_char": 25630,
      "content": "These barriers lead some computer scientists to suggest the P versus NP problem may be independent of standard axiom systems like ZFC (cannot be proved or disproved within them). An independence result could imply that either P ≠ NP and this is unprovable in (e.g.) ZFC, or that P = NP but it is unprovable in ZFC that any polynomial-time algorithms are correct. However, if the problem is undecidable even with much weaker assumptions extending the Peano axioms for integer arithmetic, then nearly polynomial-time algorithms exist for all NP problems. Therefore, assuming (as most complexity theorists do) some NP problems don't have efficient algorithms, proofs of independence with those techniques are impossible. This also implies proving independence from PA or ZFC with current techniques is no easier than proving all NP problems have efficient algorithms.",
      "char_count": 864,
      "token_estimate": 216,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "pversusnpproblem_8c43e776_c0035",
      "article_id": "pversusnpproblem_8c43e776",
      "section": "== Logical characterizations ==",
      "heading_path": "== Logical characterizations ==",
      "start_char": 25623,
      "end_char": 26561,
      "content": "== Logical characterizations == The P = NP problem can be restated as certain classes of logical statements, as a result of work in descriptive complexity. Consider all languages of finite structures with a fixed signature including a linear order relation. Then, all such languages in P are expressible in first-order logic with the addition of a suitable least fixed-point combinator. Recursive functions can be defined with this and the order relation. As long as the signature contains at least one predicate or function in addition to the distinguished order relation, so that the amount of space taken to store such finite structures is actually polynomial in the number of elements in the structure, this precisely characterizes P. Similarly, NP is the set of languages expressible in existential second-order logic—that is, second-order logic restricted to exclude universal quantification over relations, functions, and subsets.",
      "char_count": 937,
      "token_estimate": 234,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "pversusnpproblem_8c43e776_c0036",
      "article_id": "pversusnpproblem_8c43e776",
      "section": "== Logical characterizations ==",
      "heading_path": "== Logical characterizations ==",
      "start_char": 26561,
      "end_char": 27102,
      "content": "The languages in the polynomial hierarchy, PH, correspond to all of second-order logic. Thus, the question \"is P a proper subset of NP\" can be reformulated as \"is existential second-order logic able to describe languages (of finite linearly ordered structures with nontrivial signature) that first-order logic with least fixed point cannot?\". The word \"existential\" can even be dropped from the previous characterization, since P = NP if and only if P = PH (as the former would establish that NP = co-NP, which in turn implies that NP = PH).",
      "char_count": 541,
      "token_estimate": 135,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "pversusnpproblem_8c43e776_c0037",
      "article_id": "pversusnpproblem_8c43e776",
      "section": "== Polynomial-time algorithms ==",
      "heading_path": "== Polynomial-time algorithms ==",
      "start_char": 27104,
      "end_char": 28038,
      "content": "== Polynomial-time algorithms == No known algorithm for a NP-complete problem runs in polynomial time. However, there are algorithms known for NP-complete problems that if P = NP, the algorithm runs in polynomial time on accepting instances (although with enormous constants, making the algorithm impractical). However, these algorithms do not qualify as polynomial time because their running time on rejecting instances are not polynomial. The following algorithm, due to Levin (without any citation), is such an example below. It correctly accepts the NP-complete language SUBSET-SUM. It runs in polynomial time on inputs that are in SUBSET-SUM if and only if P = NP: // Algorithm that accepts the NP-complete language SUBSET-SUM. // // this is a polynomial-time algorithm if and only if P = NP. // // \"Polynomial-time\" means it returns \"yes\" in polynomial time when // the answer should be \"yes\", and runs forever when it is \"no\".",
      "char_count": 933,
      "token_estimate": 233,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "pversusnpproblem_8c43e776_c0038",
      "article_id": "pversusnpproblem_8c43e776",
      "section": "== Polynomial-time algorithms ==",
      "heading_path": "== Polynomial-time algorithms ==",
      "start_char": 28038,
      "end_char": 28928,
      "content": "// // Input: S = a finite set of integers // Output: \"yes\" if any subset of S adds up to 0. // Runs forever with no output otherwise. // Note: \"Program number M\" is the program obtained by // writing the integer M in binary, then // considering that string of bits to be a // program. Every possible program can be // generated this way, though most do nothing // because of syntax errors. FOR K = 1...∞ FOR M = 1...K Run program number M for K steps with input S IF the program outputs a list of distinct integers AND the integers are all in S AND the integers sum to 0 THEN OUTPUT \"yes\" and HALT This is a polynomial-time algorithm accepting an NP-complete language only if P = NP. \"Accepting\" means it gives \"yes\" answers in polynomial time, but is allowed to run forever when the answer is \"no\" (also known as a semi-algorithm). This algorithm is enormously impractical, even if P = NP.",
      "char_count": 890,
      "token_estimate": 222,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "pversusnpproblem_8c43e776_c0039",
      "article_id": "pversusnpproblem_8c43e776",
      "section": "== Polynomial-time algorithms ==",
      "heading_path": "== Polynomial-time algorithms ==",
      "start_char": 28929,
      "end_char": 29080,
      "content": "If the shortest program that can solve SUBSET-SUM in polynomial time is b bits long, the above algorithm will try at least 2b − 1 other programs first.",
      "char_count": 151,
      "token_estimate": 37,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "pversusnpproblem_8c43e776_c0040",
      "article_id": "pversusnpproblem_8c43e776",
      "section": "== Formal definitions ==",
      "heading_path": "== Formal definitions ==",
      "start_char": 29073,
      "end_char": 29074,
      "content": "== Formal definitions ==",
      "char_count": 24,
      "token_estimate": 6,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "pversusnpproblem_8c43e776_c0041",
      "article_id": "pversusnpproblem_8c43e776",
      "section": "== = P and NP ==",
      "heading_path": "== = P and NP ==",
      "start_char": 29090,
      "end_char": 29664,
      "content": "== = P and NP === A decision problem is a problem that takes as input some string w over an alphabet Σ, and outputs \"yes\" or \"no\". If there is an algorithm (say a Turing machine, or a computer program with unbounded memory) that produces the correct answer for any input string of length n in at most cnk steps, where k and c are constants independent of the input string, then we say that the problem can be solved in polynomial time and we place it in the class P. Formally, P is the set of languages that can be decided by a deterministic polynomial-time Turing machine.",
      "char_count": 573,
      "token_estimate": 143,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "pversusnpproblem_8c43e776_c0042",
      "article_id": "pversusnpproblem_8c43e776",
      "section": "== = P and NP ==",
      "heading_path": "== = P and NP ==",
      "start_char": 29664,
      "end_char": 30617,
      "content": "Meaning, P = { L : L = L ( M ) for some deterministic polynomial-time Turing machine M } {\\displaystyle {\\mathsf {P}}=\\{L:L=L(M){\\text{ for some deterministic polynomial-time Turing machine }}M\\}} where L ( M ) = { w ∈ Σ ∗ : M accepts w } {\\displaystyle L(M)=\\{w\\in \\Sigma ^{*}:M{\\text{ accepts }}w\\}} and a deterministic polynomial-time Turing machine is a deterministic Turing machine M that satisfies two conditions: M halts on all inputs w and there exists k ∈ N {\\displaystyle k\\in N} such that T M ( n ) ∈ O ( n k ) {\\displaystyle T_{M}(n)\\in O(n^{k})} , where O refers to the big O notation and T M ( n ) = max { t M ( w ) : w ∈ Σ ∗ , | w | = n } {\\displaystyle T_{M}(n)=\\max\\{t_{M}(w):w\\in \\Sigma ^{*},|w|=n\\}} t M ( w ) = number of steps M takes to halt on input w . {\\displaystyle t_{M}(w)={\\text{ number of steps }}M{\\text{ takes to halt on input }}w.} NP can be defined similarly using nondeterministic Turing machines (the traditional way).",
      "char_count": 953,
      "token_estimate": 238,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "pversusnpproblem_8c43e776_c0043",
      "article_id": "pversusnpproblem_8c43e776",
      "section": "== = P and NP ==",
      "heading_path": "== = P and NP ==",
      "start_char": 30618,
      "end_char": 31502,
      "content": "However, a modern approach uses the concept of certificate and verifier. Formally, NP is the set of languages with a finite alphabet and verifier that runs in polynomial time. The following defines a \"verifier\": Let L be a language over a finite alphabet, Σ. L ∈ NP if, and only if, there exists a binary relation R ⊂ Σ ∗ × Σ ∗ {\\displaystyle R\\subset \\Sigma ^{*}\\times \\Sigma ^{*}} and a positive integer k such that the following two conditions are satisfied: For all x ∈ Σ ∗ {\\displaystyle x\\in \\Sigma ^{*}} , x ∈ L ⇔ ∃ y ∈ Σ ∗ {\\displaystyle x\\in L\\Leftrightarrow \\exists y\\in \\Sigma ^{*}} such that (x, y) ∈ R and | y | ∈ O ( | x | k ) {\\displaystyle |y|\\in O(|x|^{k})} ; and the language L R = { x # y : ( x , y ) ∈ R } {\\displaystyle L_{R}=\\{x\\#y:(x,y)\\in R\\}} over Σ ∪ { # } {\\displaystyle \\Sigma \\cup \\{\\#\\}} is decidable by a deterministic Turing machine in polynomial time.",
      "char_count": 884,
      "token_estimate": 221,
      "token_start": null,
      "token_end": null
    },
    {
      "id": "pversusnpproblem_8c43e776_c0044",
      "article_id": "pversusnpproblem_8c43e776",
      "section": "== = P and NP ==",
      "heading_path": "== = P and NP ==",
      "start_char": 31503,
      "end_char": 31766,
      "content": "A Turing machine that decides LR is called a verifier for L and a y such that (x, y) ∈ R is called a certificate of membership of x in L. Not all verifiers must be polynomial-time. However, for L to be in NP, there must be a verifier that runs in polynomial time.",
      "char_count": 263,
      "token_estimate": 65,
      "token_start": null,
      "token_end": null
    }
  ],
  "questions": {
    "total_questions": 9,
    "items": [
      {
        "question": "What theorem proved that satisfiability is NP-complete?",
        "answer": "The Cook–Levin theorem.",
        "related_chunk_ids": [
          "pversusnpproblem_8c43e776_c0010"
        ],
        "category": "FACTUAL"
      },
      {
        "question": "Which cryptographic applications could be broken by a constructive and efficient solution to an NP-complete problem such as 3-SAT?",
        "answer": "A constructive and efficient solution to an NP-complete problem such as 3-SAT could break existing implementations of public-key cryptography, symmetric ciphers such as AES or 3DES, and cryptographic hashing used in applications like blockchain cryptocurrencies and software update authentication.",
        "related_chunk_ids": [
          "pversusnpproblem_8c43e776_c0026"
        ],
        "category": "FACTUAL"
      },
      {
        "question": "What is the main argument in favor of P ≠ NP mentioned in the text?",
        "answer": "The main argument in favor of P ≠ NP is the total lack of fundamental progress in the area of exhaustive search.",
        "related_chunk_ids": [
          "pversusnpproblem_8c43e776_c0021"
        ],
        "category": "FACTUAL"
      },
      {
        "question": "What does the class 'P' represent in theoretical computer science?",
        "answer": "The class 'P' represents the general class of questions that some algorithm can answer in polynomial time.",
        "related_chunk_ids": [
          "pversusnpproblem_8c43e776_c0000"
        ],
        "category": "FACTUAL"
      },
      {
        "question": "What are the two conditions that a deterministic polynomial-time Turing machine must satisfy?",
        "answer": "A deterministic polynomial-time Turing machine must halt on all inputs w, and there must exist k ∈ N such that T_M(n) ∈ O(n^k), where T_M(n) is the maximum number of steps the machine takes to halt on any input of length n.",
        "related_chunk_ids": [
          "pversusnpproblem_8c43e776_c0042"
        ],
        "category": "FACTUAL"
      },
      {
        "question": "In descriptive complexity, how is the class P characterized in terms of logic?",
        "answer": "P is characterized as the set of languages expressible in first-order logic with the addition of a suitable least fixed-point combinator, given a fixed signature including a linear order relation and at least one additional predicate or function.",
        "related_chunk_ids": [
          "pversusnpproblem_8c43e776_c0035"
        ],
        "category": "FACTUAL"
      },
      {
        "question": "How did early discussions by John Nash and Kurt Gödel anticipate the formalization of the P versus NP problem, and what were the potential implications they identified for computational complexity theory?",
        "answer": "Before the formal statement of the P versus NP problem in 1971, John Nash speculated in 1955 that the time required to break complex codes would grow exponentially with key length, implying P ≠ NP since verifying a key could be done in polynomial time. In 1956, Kurt Gödel questioned whether theorem-proving could be solved in quadratic or linear time and noted that, if so, mathematical proof discovery could be automated. These early discussions anticipated the formalization of the P versus NP problem and highlighted its significance for computational complexity theory, particularly regarding the resources (time and space) required to solve problems and the potential for automating complex tasks.",
        "related_chunk_ids": [
          "pversusnpproblem_8c43e776_c0003",
          "pversusnpproblem_8c43e776_c0004",
          "pversusnpproblem_8c43e776_c0005"
        ],
        "category": "LONG_ANSWER"
      },
      {
        "question": "Why is the P versus NP problem considered so significant in computer science and other fields?",
        "answer": "The P versus NP problem is significant because it addresses whether every problem whose solution can be quickly verified can also be quickly solved, which is a foundational question in theoretical computer science. If P ≠ NP, as is widely believed, it would mean there are problems that are much harder to solve than to verify, impacting not only computational theory but also fields such as mathematics, cryptography, algorithm research, artificial intelligence, game theory, multimedia processing, philosophy, and economics. Its importance is further underscored by its status as one of the seven Millennium Prize Problems, each carrying a $1,000,000 prize for a correct solution.",
        "related_chunk_ids": [
          "pversusnpproblem_8c43e776_c0000",
          "pversusnpproblem_8c43e776_c0001"
        ],
        "category": "INTERPRETATION"
      },
      {
        "question": "How did early discussions by John Nash and Kurt Gödel anticipate the formal statement of the P versus NP problem, and what potential consequences did they foresee?",
        "answer": "Before the formal statement of the P versus NP problem in 1971, John Nash speculated in 1955 that the time required to break complex codes would grow exponentially with key length, implying what is now called P ≠ NP, since verifying a key could be done in polynomial time. Similarly, in 1956, Kurt Gödel questioned whether theorem-proving could be solved in quadratic or linear time and noted that if it could, mathematical proof discovery could be automated. Both Nash and Gödel anticipated key aspects and consequences of the P versus NP problem, including the difficulty of proof and the implications for automation and cryptography.",
        "related_chunk_ids": [
          "pversusnpproblem_8c43e776_c0003",
          "pversusnpproblem_8c43e776_c0004"
        ],
        "category": "INTERPRETATION"
      }
    ]
  },
  "metadata": {
    "export_date": "2025-07-28T12:09:33.293Z",
    "content_format": "markdown",
    "total_chunks": 45,
    "description": "Complete article dataset including content, chunks, and generated questions"
  }
}